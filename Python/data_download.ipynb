{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a06c82b1-50d4-4999-a7ec-c30a6fd5c3a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "country = \"ecuador\"\n",
    "\n",
    "import io,  unicodedata, os, re, urllib3, requests, datetime, re\n",
    "import pandas as pd ; import numpy as np\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "from io import BytesIO\n",
    "\n",
    "d = os.getcwd()+\"/../\"\n",
    "PATH_RAW = f\"{d}/raw\"\n",
    "PATH_FORMAT = f\"{d}/data\"\n",
    "folder_spec = PATH_RAW\n",
    "\n",
    "from urllib.request import urlopen\n",
    "\n",
    "hdr = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537'}\n",
    "urllib3.disable_warnings()\n",
    "\n",
    "import tika\n",
    "from tika import parser    \n",
    "import tabula\n",
    "import zipfile\n",
    "import xlrd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8024d736-bb4a-48f6-8e6d-ac154d7d792e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## BCE website"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411885c9-99b0-400c-be20-73bbe7f1b2c7",
   "metadata": {},
   "source": [
    "- GDP\n",
    "\n",
    "PIB: Acceder al website del BCE/Estadisticas/Sector Real https://www.bce.fin.ec/informacioneconomica/sector-real\n",
    "\n",
    "Cuentas Nacionales > Base Movil 2018 > Cuentas Nacionales Trimestrales https://contenido.bce.fin.ec/documentos/informacioneconomica/cuentasnacionales/ix_cuentasnacionalestrimestrales.html\n",
    "\n",
    "- Exportaciones mineras\n",
    "\n",
    "- Exportaciones de hidrocarburos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5888b2d2-7542-4b50-a738-9dabc0ee7af6",
   "metadata": {},
   "source": [
    "Extraigo datos de Niveles de Volumen Encadenados, 2018=100 Miles de US Dolares adjustados de estacionalidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42abd9d9-ce6f-4863-9535-71ccedf0b7c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df0 = pd.read_csv(f'{PATH_RAW}/bce_gdp.csv', parse_dates=True, index_col='date')\n",
    "\n",
    "url = \"https://contenido.bce.fin.ec/documentos/informacioneconomica/cuentasnacionales/ix_cuentasnacionalestrimestrales.html\"\n",
    "\n",
    "r = requests.get(url, headers=hdr, verify=False)\n",
    "r = r.content\n",
    "\n",
    "soup = BeautifulSoup(r, 'html.parser')\n",
    "links = soup.find_all('a')\n",
    "\n",
    "excel_links = [ link.get('href') for link in links if \"xls\" in link.get('href') and \"tou\" in link.get('href') ]\n",
    "excel_links = [ link for link in excel_links if \"prel\" not in link ]\n",
    "excel_links\n",
    "\n",
    "latest = \"\"\n",
    "for link in excel_links :\n",
    "    if latest == \"\" : latest = link\n",
    "    else :\n",
    "        if int(link.split(\"_\")[-2]) > int(latest.split(\"_\")[-2]) : latest = link\n",
    "\n",
    "from io import BytesIO\n",
    "\n",
    "df = pd.read_excel( BytesIO(requests.get(latest, headers=hdr, verify=False).content) , sheet_name=\"Dem_Cad_ajus\", skiprows=8, skipfooter=1)\n",
    "df.dropna(inplace=True)\n",
    "df.columns = df.columns.str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8').str.lower()\n",
    "df.columns = df.columns.str.replace(\".\",\"\")\n",
    "df = df[['variables','pib']]\n",
    "df.variables = df.variables.str.replace(r'[a-z()]','', regex=True)\n",
    "\n",
    "quarter_mapping = {\n",
    "    '.IV': '-Q4',\n",
    "    '.III': '-Q3',\n",
    "    '.II': '-Q2',\n",
    "    '.I': '-Q1',    \n",
    "}\n",
    "\n",
    "for roman, quarter in quarter_mapping.items():\n",
    "    df['variables'] = df['variables'].str.replace(roman, quarter)\n",
    "df.variables = df.variables.str.replace(r'.','').str.strip()\n",
    "\n",
    "def quarter_to_date(quarter):\n",
    "    year, q = quarter.split('-')\n",
    "    month = {'Q1': '01', 'Q2': '04', 'Q3': '07', 'Q4': '10'}[q]\n",
    "    return pd.to_datetime(f\"{year}-{month}-01\")\n",
    "\n",
    "df['date'] = df['variables'].apply(quarter_to_date)\n",
    "df = df[['date','pib']]\n",
    "df.set_index('date', inplace=True)\n",
    "df.rename(columns = { 'pib' : 'gdp_movil' } , inplace=True)\n",
    "\n",
    "df = pd.merge(df0, df, left_index=True, right_index=True, how='outer', suffixes=('_0', '_1'))\n",
    "df['gdp_movil'] = df.apply(lambda row: row['gdp_movil_1'] if pd.isna(row['gdp_movil_0']) or row['gdp_movil_0'] != row['gdp_movil_1'] else row['gdp_movil_0'], axis=1)\n",
    "df = df[['gdp_movil']]\n",
    "\n",
    "df.to_csv(f'{PATH_RAW}/bce_gdp.csv')\n",
    "print(f\"Updated GDP: {df.index.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50be35f3-5082-4067-9fee-c9062eb67e47",
   "metadata": {},
   "source": [
    "Exportaciones Mineras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badec92c-46d1-4378-8033-8ef1c54c368d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "url = \"https://contenido.bce.fin.ec/documentos/Estadisticas/Hidrocarburos/ExportacionesAnuales.xlsx\"\n",
    "\n",
    "df = pd.ExcelFile(BytesIO(requests.get(url, headers=hdr, verify=False).content))\n",
    "df = pd.read_excel(df, sheet_name=\"Exportaciones Mineras\", skiprows=9, header=[0,1,2], skipfooter=10)\n",
    "df.columns = df.columns.map('{0[0]}_{0[1]}_{0[2]}'.format)\n",
    "df.columns = df.columns.astype(\"str\").str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8').str.lower()\n",
    "\n",
    "for col in df.columns :\n",
    "    if \"0_level_1\" in col :\n",
    "        df.rename(columns = { col : 'year'} , inplace=True)\n",
    "    elif \"1_level_1\" in col :\n",
    "        df.rename(columns = { col : 'month'} , inplace=True)\n",
    "\n",
    "df.dropna(subset='month', inplace=True)\n",
    "df['year'] = df['year'].ffill()\n",
    "\n",
    "df.month = df.month.astype(\"str\").str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8').str.lower()\n",
    "\n",
    "df = df[~df['month'].str.contains('-')]\n",
    "\n",
    "months = {'enero': '01', 'febrero': '02', 'marzo':'03', 'abril':'04', 'mayo': '05', 'junio': '06','julio': '07','agosto': '08','septiembre': '09','octubre': '10','noviembre': '11','diciembre': '12'}\n",
    "df['month'] = df['month'].astype(str).str.lower().replace(months, regex=True)\n",
    "\n",
    "df[\"date\"] = pd.to_datetime(df[[\"year\",\"month\"]].assign(DAY=1))\n",
    "\n",
    "df.set_index('date', inplace=True)\n",
    "df = df[ [col for col in df.columns if 'kilogram' in col] ]\n",
    "df.rename(columns=lambda x: x.replace('kilogramos', 'kg'), inplace=True)\n",
    "df.rename(columns=lambda x: x.replace('_', ' '), inplace=True)\n",
    "df.rename(columns=lambda x: x.replace('en todas sus formas', ''), inplace=True)\n",
    "df.rename(columns=lambda x: x.replace('los demas', ''), inplace=True)\n",
    "df.rename(columns=lambda x: re.sub(r'\\s*\\(.*?\\)\\s*', ' ', x), inplace=True)\n",
    "df.rename(columns=lambda x: re.sub(r'\\s{2,}', ' ', x), inplace=True)\n",
    "df.rename(columns=lambda x: x.replace('*', ''), inplace=True)\n",
    "\n",
    "df.rename( columns=lambda x: re.sub(r'\\b(\\w+)\\b\\s+\\b\\1\\b', r'\\1', x ) , inplace=True ) \n",
    "\n",
    "df.columns = df.columns.astype(\"str\").str.strip().str.lower()\n",
    "\n",
    "prefixes = set(col.split(' ')[0] for col in df.columns)\n",
    "for prefix in prefixes:\n",
    "    df[f\"{prefix} total kg exports\"] = df.filter(like=prefix).sum(axis=1)\n",
    "    \n",
    "df.to_csv(f\"{PATH_RAW}/bce_export.csv\")\n",
    "print(f\"Updated Exports: {df.index.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8678a4-6846-4b73-af94-0e52988e4c19",
   "metadata": {},
   "source": [
    "Exportaciones de hidrocarburos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ad8ea1-e2e1-48e0-9622-f021fb575f24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "url = \"https://contenido.bce.fin.ec/documentos/Estadisticas/Hidrocarburos/SerieCifrasPetroleras.xlsx\"\n",
    "\n",
    "df = pd.read_excel( BytesIO(requests.get(url, headers=hdr, verify=False).content) , header=[1,2])\n",
    "df.columns = df.columns.map('{0[0]}_{0[1]}'.format)\n",
    "\n",
    "df.rename(columns = {\"Unnamed: 0_level_0_Unnamed: 0_level_1\" : \"var0\"}, inplace=True)\n",
    "df.rename(columns = {\"Unnamed: 1_level_0_Unnamed: 1_level_1\" : \"var1\"}, inplace=True)\n",
    "\n",
    "df.var0 = df.var0.astype(\"str\").str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8').str.lower().str.strip()\n",
    "df.var1 = df.var1.astype(\"str\").str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8').str.lower().str.strip()\n",
    "\n",
    "df['var0'] = np.where(df['2007_ene'].notna(), np.nan, df['var0'])\n",
    "df['var0'] = df['var0'].ffill()\n",
    "\n",
    "df = df[~df['var1'].str.contains('tasa de crecimiento', case=False, na=False)]\n",
    "\n",
    "\n",
    "df[\"var1\"] = df[\"var1\"].str.replace(\"-\", \"\").str.strip()\n",
    "v = {'produccion promedio diaria': 'production_bpd_oil',\n",
    " 'total exportaciones de petroleo' : \"export_bdp\",\n",
    " 'gasolina super' : 'production_bpd_gassuper',\n",
    " 'gasolina extra' : 'production_bpd_gasextra', \n",
    " 'extra con ethanol' : 'production_bpd_ecopais',\n",
    " 'ecoplus' :'production_bpd_ecoplus',\n",
    " 'diesel' : 'production_bpd_diesel',\n",
    " 'fuel oil # 4' : 'production_bpd_fueloil4',\n",
    " 'fuel oil # 6' : 'production_bpd_fueloil6' ,\n",
    " 'gas licuado de petroleo' : 'production_bpd_lpg',\n",
    " 'otros' : 'production_bpd_other',\n",
    " 'consumo promedio diario' : \"consumption_bdp\",\n",
    " 'precio' : 'price_oil'\n",
    "}\n",
    "\n",
    "df[\"var1\"] = df[\"var1\"].replace(v, regex=True)\n",
    "\n",
    "\n",
    "df = df[df['var1'].str.contains('production_') | df['var1'].str.contains('price_') | df['var1'].str.contains('consumption_')  | df['var1'].str.contains('export_')]\n",
    "\n",
    "\n",
    "df = df.loc[ (df.index==2) | (df.index==48) |(df.index>60) & (df.index<69) | (df.index==77) | (df.index == 88) | (df.index == 89) | (df.index == 90) | (df.index == 95) ]\n",
    "\n",
    "df.var1 = df.var1.str.replace(r'\\s*\\(.*?\\)\\s*', '', regex=True)\n",
    "df.drop('var0', axis=1, inplace=True)\n",
    "\n",
    "df.rename(columns = {\"var1\": \"variable\"}, inplace=True)\n",
    "df = pd.melt(df, id_vars=\"variable\", var_name=\"date\")\n",
    "\n",
    "months = {'ene': '01', 'feb': '02', 'mar':'03', 'abr':'04', 'may': '05', 'jun': '06','jul': '07','ago': '08','sep': '09','oct': '10','nov': '11','dic': '12','dec': '12'}\n",
    "df[\"date\"] = df[\"date\"].astype(str).str.lower().replace(months, regex=True)\n",
    "df[\"date\"] = df[\"date\"].astype(str).str.lower().replace(r'(\\d{4})_\\d{4}', r'\\1', regex=True)\n",
    "df = df[~df[\"date\"].str.contains(r'\\d{4}_\\d{2}.', r'show', regex=True)]\n",
    "df[\"date\"] = df[\"date\"].astype(str).str.lower().replace(r'(\\d{4})_(\\d{2})', r'\\1-\\2-01', regex=True)\n",
    "df.date = pd.to_datetime(df['date'], format=\"%Y-%m-%d\")\n",
    "df.set_index('date', inplace=True)\n",
    "\n",
    "df.dropna(subset='value', inplace=True)\n",
    "\n",
    "df = pd.pivot(df, columns=\"variable\", values=\"value\")\n",
    "\n",
    "df.to_csv(f\"{PATH_RAW}/bce_oil.csv\")\n",
    "print(\"Oil updated\")\n",
    "print(df.index.max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ac3f73-4345-408e-932b-808b59cb7d43",
   "metadata": {},
   "source": [
    "**Expectativas**\n",
    "\n",
    "- Indice de Expectativas de la Economia\n",
    "- Indice de Actividad Economica Coyuntural (IDEAC)\n",
    "- Indice de Confianza del Consumidor\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "87e54075-1023-498f-bb8f-f4e8c7d487f9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "url = \"https://contenido.bce.fin.ec/documentos/PublicacionesNotas/Catalogo/Encuestas/EOE/eoeindice.htm\"\n",
    "r = requests.get(url=url, verify=False).content\n",
    "\n",
    "soup = BeautifulSoup(r, 'html.parser')\n",
    "links = soup.find_all('a')\n",
    "\n",
    "excel_links = [ link.get('href') for link in links if \"iee\" in link.get('href')]\n",
    "latest_url = None\n",
    "\n",
    "for url in excel_links :\n",
    "    if latest_url == None : latest_url = url\n",
    "    elif pd.to_datetime(url.replace('.html','')[-6:], format = \"%Y%d\") > pd.to_datetime(latest_url.replace('.html','')[-6:], format = \"%Y%d\") : latest_url = url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4696f00e-2b29-4868-873e-396d0cf44e43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "get = \"https://contenido.bce.fin.ec/documentos/PublicacionesNotas/Catalogo/Encuestas/EOE/IEE_Nueva_Metodologia.xlsx\"\n",
    "\n",
    "df = pd.read_excel( BytesIO(requests.get(get, headers=hdr, verify=False).content) , skiprows=7 , parse_dates=True )\n",
    "df.dropna(inplace = True)\n",
    "df.columns = df.columns.astype(\"str\").str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8').str.lower().str.strip()\n",
    "\n",
    "df['date'] = pd.to_datetime(df['fecha'])\n",
    "df.set_index('date', inplace=True)\n",
    "df.columns = df.columns.str.replace(r'\\s*\\(.*?\\)\\s*', '', regex=True)\n",
    "df.drop('fecha', axis = 1, inplace=True)\n",
    "\n",
    "df = df.rename(columns=lambda x: f\"iee_{x}\" if \"iee\" not in x else x)\n",
    "df.columns = df.columns.astype(\"str\").str.replace(' ', '_')\n",
    "df.to_csv(f\"{PATH_RAW}/bce_iee.csv\")\n",
    "print(\"IEE updated\")\n",
    "print(df.index.max())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d8af1d7a-63a8-495c-9af7-8a5e368ccf5d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "# https://www.bce.fin.ec/index.php/component/k2/item/313-indice-de-actividad-econ%C3%B3mica-coyuntural-ideac\n",
    "get = \"https://contenido.bce.fin.ec/documentos/PublicacionesNotas/Catalogo/IEMensual/Adelantos/IEM-452-e.xlsx\"\n",
    "\n",
    "df = pd.read_excel( BytesIO(requests.get(get, headers=hdr, verify=False).content) , skiprows=7 , parse_dates=True , skipfooter= 1 )\n",
    "\n",
    "df.dropna(how='all', inplace=True)\n",
    "df.columns = df.columns.astype(\"str\").str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8').str.lower().str.strip()\n",
    "df.rename( columns = { 'unnamed: 0' : 'month' } , inplace=True)\n",
    "\n",
    "df = pd.melt(df, id_vars=\"month\", var_name=\"year\")\n",
    "months = {'ene': '01', 'feb': '02', 'mar':'03', 'abr':'04', 'may': '05', 'jun': '06','jul': '07','ago': '08','sep': '09','oct': '10','nov': '11','dic': '12','dec': '12'}\n",
    "df[\"month\"] = df[\"month\"].astype(str).str.lower().replace(months, regex=True)\n",
    "df[\"date\"] = pd.to_datetime(df[['year', 'month']].assign(DAY=1), format='%b')\n",
    "df.set_index('date', inplace=True)\n",
    "\n",
    "df = df[['value']]\n",
    "df.rename(columns = { 'value' : 'ideac' } , inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "try :\n",
    "    df0 = pd.read_csv(f\"{PATH_RAW}/bce_ideac.csv\" , parse_dates=True, index_col='date')\n",
    "    df = df.merge(df0, left_index=True, right_index=True, how='outer')\n",
    "    df['ideac'] = df['ideac_x'].fillna(df['ideac_y'])\n",
    "    df[['ideac']]\n",
    "    df.to_csv(f\"{PATH_RAW}/bce_ideac.csv\")\n",
    "except :\n",
    "    df.to_csv(f\"{PATH_RAW}/bce_ideac.csv\")\n",
    "\n",
    "print(\"IDEAC updated\")\n",
    "print(df.index.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672ae409-ed9e-44c4-b0a2-cf344aa257f3",
   "metadata": {},
   "source": [
    "**Indice de confianza al consumidor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbba833e-d503-4619-b6f5-6faae9ecf5f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "url = \"https://contenido.bce.fin.ec/documentos/Estadisticas/SectorReal/Previsiones/IndCoyuntura/mensual/ICC_indice.htm\"\n",
    "r = requests.get(url=url, verify=False).content\n",
    "\n",
    "soup = BeautifulSoup(r, 'html.parser')\n",
    "links = soup.find_all('a')\n",
    "\n",
    "excel_links = [ link.get('href') for link in links if \"icc\" in link.get('href').lower() and \"pdf\" not in link.get('href').lower()]\n",
    "\n",
    "try :\n",
    "    df0 = pd.read_csv(f\"{PATH_RAW}/bce_icc.csv\", parse_dates=True, index_col='date')\n",
    "except :\n",
    "    df0 = pd.DataFrame()\n",
    "\n",
    "\n",
    "latest_url = []\n",
    "for url in excel_links :\n",
    "    if len(df0) == 0 : latest_url.append(url)\n",
    "    elif pd.to_datetime(url.replace('.html','')[-6:], format = \"%Y%m\") > df0.index.max() :  latest_url.append(url)\n",
    "\n",
    "for url in latest_url :\n",
    "    r = requests.get(url=url, verify=False).content\n",
    "    df = pd.read_html(r)[0][['Indicador Global']]\n",
    "    df['date'] = pd.to_datetime(url.replace('.html','')[-6:], format = \"%Y%m\")\n",
    "    df.set_index('date', inplace=True)\n",
    "    df.rename( columns = {'Indicador Global' : 'icc'} , inplace=True)\n",
    "    df['icc'] = df['icc']/100\n",
    "    df0 = pd.concat([df0,df])\n",
    "\n",
    "df0.to_csv(f\"{PATH_RAW}/bce_icc.csv\")\n",
    "print(\"ICC updated\")\n",
    "print(df.index.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf1f314-baed-4aa0-a949-c346da925a07",
   "metadata": {},
   "source": [
    "**Reservas Internacionales**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cea0508-31c5-4af9-9dd4-d1de662c6282",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://contenido.bce.fin.ec/home1/estadisticas/bolsemanal/IndiceBMS.htm\"\n",
    "\n",
    "r = requests.get(url, headers=hdr, verify=False)\n",
    "r = r.content\n",
    "\n",
    "soup = BeautifulSoup(r, 'html.parser')\n",
    "links = soup.find_all('a')\n",
    "\n",
    "excel_links = [ link.get('href') for link in links if \"xls\" in link.get('href') ]\n",
    "\n",
    "def extract_date(url):\n",
    "    date_match = re.search(r'BMS_(\\d{8})', url)\n",
    "    if date_match:\n",
    "        date_str = date_match.group(1)\n",
    "        return datetime.strptime(date_str, '%d%m%Y')\n",
    "    return None\n",
    "\n",
    "excel_links = [ (url, extract_date(url) ) for url in excel_links ]\n",
    "excel_links = [ pair for pair in excel_links if pair[1] is not None ]\n",
    "\n",
    "get = max(excel_links, key=lambda x: x[1])[0]\n",
    "df0 = pd.ExcelFile( BytesIO(requests.get(get, headers=hdr, verify=False).content) )\n",
    "\n",
    "df = pd.read_excel( df0 , sheet_name='IMS1', skiprows=6, skipfooter=13, header=[0,1,2])\n",
    "\n",
    "df.columns = df.columns.map('{0[0]}_{0[1]}_{0[2]}'.format)\n",
    "df.columns = df.columns.astype(\"str\").str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8').str.lower().str.strip()\n",
    "\n",
    "df['year'] = df['periodo_unnamed: 0_level_1_unnamed: 0_level_2'].ffill()\n",
    "months = {'enero': '01', 'febrero': '02', 'marzo':'03', 'abril':'04', 'mayo': '05', 'junio': '06','julio': '07','agosto': '08','septiembre': '09','octubre': '10','noviembre': '11','diciembre': '12', \n",
    "          'ene': '01', 'feb': '02', 'mar':'03', 'abr':'04', 'may': '05', 'jun': '06','jul': '07','ago': '08','sep': '09','oct': '10','nov': '11','dic': '12','dec': '12' }\n",
    "df['month'] = df['periodo_unnamed: 1_level_1_unnamed: 1_level_2'].astype(str).str.lower().replace(months, regex=True)\n",
    "\n",
    "df.dropna(subset='year', inplace=True)\n",
    "df.year = df.year.astype(int)\n",
    "df['day'] = df['periodo_unnamed: 2_level_1_unnamed: 2_level_2']\n",
    "df.dropna(subset='day', inplace=True)\n",
    "df.day = df.day.astype(int)\n",
    "df['date'] = pd.to_datetime(df[['year', 'month', 'day']], errors='coerce')\n",
    "\n",
    "df.dropna(subset='date', inplace=True)\n",
    "df['date'] = pd.to_datetime( df['date'] )\n",
    "df.columns = df.columns.str.replace(r'\\(.*?\\)', '', regex=True).str.strip()\n",
    "\n",
    "df = df[[ col for col in df.columns if \n",
    "         \"banco central\" in col \n",
    "         or \"panorama financiero\" in col \n",
    "         or \"tasas de interes\" in col\n",
    "         or \"date\" in col ]]\n",
    "\n",
    "df.columns = df.columns.str.replace(r'_unnamed: \\d+_level_\\d+', '', regex=True).str.strip()\n",
    "df.columns = df.columns.str.replace(r'\\nporcentajes_', ' ', regex=True).str.strip()\n",
    "df.columns = df.columns.str.replace(r'_', ' ', regex=True).str.strip()\n",
    "df.set_index('date', inplace=True)\n",
    "\n",
    "# Make all columns into numeric\n",
    "df = df.applymap(lambda x: pd.to_numeric(x, errors='coerce'))\n",
    "df.dropna(axis=1, how='all', inplace=True)\n",
    "\n",
    "df = df.resample('MS').last()\n",
    "df.columns = df.columns.str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
    "df.to_csv(f\"{PATH_RAW}/bce_ims1.csv\")\n",
    "print(\"RRII updated\")\n",
    "print(df.index.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26e804d-0c4d-4057-b1ce-78bb2e59d689",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel( df0 , sheet_name='IMS1.1', skiprows=6, skipfooter=13, header=[0,1,2])\n",
    "df.columns = df.columns.map('{0[0]}_{0[1]}_{0[2]}'.format)\n",
    "df.columns = df.columns.astype(\"str\").str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8').str.lower().str.strip()\n",
    "\n",
    "\n",
    "df['year'] = df['periodo_unnamed: 0_level_1_unnamed: 0_level_2'].ffill()\n",
    "months = {'enero': '01', 'febrero': '02', 'marzo':'03', 'abril':'04', 'mayo': '05', 'junio': '06','julio': '07','agosto': '08','septiembre': '09','octubre': '10','noviembre': '11','diciembre': '12', \n",
    "          'ene': '01', 'feb': '02', 'mar':'03', 'abr':'04', 'may': '05', 'jun': '06','jul': '07','ago': '08','sep': '09','oct': '10','nov': '11','dic': '12','dec': '12' }\n",
    "df['month'] = df['periodo_unnamed: 1_level_1_unnamed: 1_level_2'].astype(str).str.lower().replace(months, regex=True)\n",
    "\n",
    "df.dropna(subset='year', inplace=True)\n",
    "df.year = df.year.astype(int)\n",
    "\n",
    "df[\"date\"] = pd.to_datetime(df[['year', 'month']].assign(DAY=1), format='%b')\n",
    "df.dropna(subset='date', inplace=True)\n",
    "df['date'] = pd.to_datetime( df['date'] )\n",
    "df.columns = df.columns.str.replace(r'\\(.*?\\)', '', regex=True).str.strip()\n",
    "\n",
    "df.columns = df.columns.str.replace(r'_unnamed: \\d+_level_\\d+', '', regex=True).str.strip()\n",
    "df.columns = df.columns.str.replace(r'_', ' ', regex=True).str.strip()\n",
    "df.set_index('date', inplace=True)\n",
    "\n",
    "df.columns = df.columns.str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
    "\n",
    "target = [\"especies monetarias en circulacion\", \n",
    "\"moneda fraccionaria\" ,\n",
    "\"dinero electronico\" ,\n",
    "\"depositos a la vista\", \n",
    "\"oferta monetaria m1\",\n",
    "\"cuasidinero\",\n",
    "\"liquidez total m2\",\n",
    "\"reservas bancarias\",\n",
    "\"base monetaria bm\",\n",
    "\"multiplicador m1/bm\",\n",
    "\"multiplicador m2/bm\"]\n",
    "\n",
    "def rename_columns(df, target_list):\n",
    "    new_columns = {}\n",
    "    \n",
    "    for column in df.columns:\n",
    "        for target_str in target_list:\n",
    "            if target_str in column:\n",
    "                new_columns[column] = target_str\n",
    "                break\n",
    "    \n",
    "    df.rename(columns=new_columns, inplace=True)\n",
    "rename_columns(df, target)\n",
    "df = df[target]\n",
    "\n",
    "df.to_csv(f\"{PATH_RAW}/bce_ims11.csv\")\n",
    "print(\"Oferta Monetaria updated\")\n",
    "print(df.index.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c305eb9f-cfde-4ff3-96e3-39abf8e9d741",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel( df0 , sheet_name='IMS2', skiprows=6, skipfooter=2, header=[0,1])\n",
    "df.columns = df.columns.map('{0[0]}_{0[1]}'.format)\n",
    "df.columns = df.columns.astype(\"str\").str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8').str.lower().str.strip()\n",
    "df['variable'] = df[ [col for col in df.columns if \"unnamed: 0\" in col] ]\n",
    "df['variable'] = df['variable'].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8').str.lower().str.strip()\n",
    "\n",
    "# Remove parentheses\n",
    "df['variable'] = df['variable'].str.replace(r'\\(.*?\\)', '', regex=True).str.strip()\n",
    "df.dropna(subset='variable', inplace=True)\n",
    "\n",
    "df['variable'] = df['variable'].str.replace( r'[.\\d]+' , '', regex=True).str.strip()\n",
    "df['variable'] = df['variable'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
    "\n",
    "df.drop([ col for col in df.columns if \"unnamed\" in col ], axis=1, inplace=True)\n",
    "\n",
    "df = pd.melt(df, id_vars='variable', var_name='date', value_name='value')\n",
    "\n",
    "months = {'enero': '01', 'febrero': '02', 'marzo':'03', 'abril':'04', 'mayo': '05', 'junio': '06','julio': '07','agosto': '08','septiembre': '09','octubre': '10','noviembre': '11','diciembre': '12', \n",
    "          'ene': '01', 'feb': '02', 'mar':'03', 'abr':'04', 'may': '05', 'jun': '06','jul': '07','ago': '08','sep': '09','oct': '10','nov': '11','dic': '12','dec': '12' }\n",
    "\n",
    "df['date'] = df['date'].astype(str).str.lower().replace(months, regex=True)\n",
    "df['date'] = df['date'].str.replace('_', '-')\n",
    "\n",
    "def remove_repeated_year(date_str):\n",
    "    # Match the format 'YYYY-YYYY-rest' or 'YYYY-rest'\n",
    "    match = re.match(r'(\\d{4})-(\\d{4})-(.*)', date_str)\n",
    "    if match and match.group(1) == match.group(2):\n",
    "        return f\"{match.group(1)}-{match.group(3)}\"\n",
    "    return date_str\n",
    "df['date'] = df['date'].apply(remove_repeated_year)\n",
    "df['date'] = df['date'].replace(r'^(\\d{4}-\\d{2})$', r'\\1-01', regex=True)\n",
    "\n",
    "def parse_date(date_str):\n",
    "    try:\n",
    "        return pd.to_datetime(date_str, format='%Y-%m-%d %H:%M:%S')\n",
    "    except ValueError:\n",
    "        try:\n",
    "            return pd.to_datetime(date_str, format='%Y-%m-%d')\n",
    "        except ValueError:\n",
    "            return pd.NaT\n",
    "df['date'] = df['date'].apply(parse_date)\n",
    "df.date = pd.to_datetime(df.date)\n",
    "df.set_index('date', inplace=True)\n",
    "\n",
    "df = df.pivot(columns='variable', values='value')\n",
    "df.rename(columns = {'ri' : 'reservas internacionales'} , inplace=True)\n",
    "\n",
    "df.to_csv(f\"{PATH_RAW}/bce_ims2.csv\")\n",
    "print(\"Monetary\")\n",
    "print(df.index.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3e3ca8-2bd7-47f4-ad06-8d94569c971d",
   "metadata": {},
   "source": [
    "**Captaciones (IMS13 & IMS7)**"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7d12a636-f076-4b07-850c-f3bd2b2d879d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# IMS7: Cuales depositos?\n",
    "\n",
    "df = pd.read_excel( df0 , sheet_name='IMS7', skiprows=5, skipfooter=2, header=[0,1])\n",
    "df.columns = df.columns.map('{0[0]}_{0[1]}'.format)\n",
    "df.columns = df.columns.astype(\"str\").str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8').str.lower().str.strip()\n",
    "df['variable'] = df[ [col for col in df.columns if \"unnamed: 0\" in col] ]\n",
    "df['variable'] = df['variable'].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8').str.lower().str.strip()\n",
    "\n",
    "df['variable'] = df['variable'].str.replace(r'\\(.*?\\)', '', regex=True).str.strip()\n",
    "df.dropna(subset='variable', inplace=True)\n",
    "\n",
    "df['variable'] = df['variable'].str.replace( r'[.\\d]+' , '', regex=True).str.strip()\n",
    "df['variable'] = df['variable'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b1d279-9bcc-40d1-b88e-87c83f17f0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel( df0 , sheet_name='IMS13', skiprows=8, skipfooter=2, header=[0,1])\n",
    "df.columns = df.columns.map('{0[0]}_{0[1]}'.format)\n",
    "df.columns = df.columns.astype(\"str\").str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8').str.lower().str.strip()\n",
    "df['variable'] = df[ [col for col in df.columns if \"unnamed: 0\" in col] ]\n",
    "df['variable'] = df['variable'].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8').str.lower().str.strip()\n",
    "\n",
    "df['variable'] = df['variable'].str.replace(r'\\(.*?\\)', '', regex=True).str.strip()\n",
    "df.dropna(subset='variable', inplace=True)\n",
    "\n",
    "df['variable'] = df['variable'].str.replace( r'[.\\d]+' , '', regex=True).str.strip()\n",
    "df['variable'] = df['variable'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
    "\n",
    "df.drop([ col for col in df.columns if \"unnamed\" in col ], axis=1, inplace=True)\n",
    "\n",
    "df = pd.melt(df, id_vars='variable', var_name='date', value_name='value')\n",
    "\n",
    "months = {'enero': '01', 'febrero': '02', 'marzo':'03', 'abril':'04', 'mayo': '05', 'junio': '06','julio': '07','agosto': '08','septiembre': '09','octubre': '10','noviembre': '11','diciembre': '12', \n",
    "          'ene': '01', 'feb': '02', 'mar':'03', 'abr':'04', 'may': '05', 'jun': '06','jul': '07','ago': '08','sep': '09','oct': '10','nov': '11','dic': '12','dec': '12' }\n",
    "\n",
    "df['date'] = df['date'].astype(str).str.lower().replace(months, regex=True)\n",
    "df['date'] = df['date'].str.replace('_', '-')\n",
    "\n",
    "def remove_repeated_year(date_str):\n",
    "    # Match the format 'YYYY-YYYY-rest' or 'YYYY-rest'\n",
    "    match = re.match(r'(\\d{4})-(\\d{4})-(.*)', date_str)\n",
    "    if match and match.group(1) == match.group(2):\n",
    "        return f\"{match.group(1)}-{match.group(3)}\"\n",
    "    return date_str\n",
    "df['date'] = df['date'].apply(remove_repeated_year)\n",
    "df['date'] = df['date'].replace(r'^(\\d{4}-\\d{2})$', r'\\1-01', regex=True)\n",
    "\n",
    "def parse_date(date_str):\n",
    "    try:\n",
    "        return pd.to_datetime(date_str, format='%Y-%m-%d %H:%M:%S')\n",
    "    except ValueError:\n",
    "        try:\n",
    "            return pd.to_datetime(date_str, format='%Y-%m-%d')\n",
    "        except ValueError:\n",
    "            return pd.NaT\n",
    "df['date'] = df['date'].apply(parse_date)\n",
    "df.date = pd.to_datetime(df.date)\n",
    "df.set_index('date', inplace=True)\n",
    "\n",
    "df.dropna(subset='value', inplace=True)\n",
    "df = df[df['variable'].str.contains('depositos vista panorama') | df['variable'].str.contains('cuasidinero') ]\n",
    "\n",
    "df = df.pivot(columns='variable', values='value')\n",
    "\n",
    "df.rename( columns=lambda x: f\"ims13_captaciones_{x.replace(' ', '_')}\" , inplace=True)\n",
    "df = pd.DataFrame(df.resample(\"MS\").last()).sort_index()\n",
    "df.to_csv(f\"{PATH_RAW}/bce_ims13.csv\")\n",
    "print(f\"Depositos updated: {df.index.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c83875-a0b1-42bd-ab98-04b2d0ee46cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel( df0 , sheet_name='IMS14', skiprows=8, skipfooter=2, header=[0,1])\n",
    "df.columns = df.columns.map('{0[0]}_{0[1]}'.format)\n",
    "df.columns = df.columns.astype(\"str\").str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8').str.lower().str.strip()\n",
    "df['variable'] = df[ [col for col in df.columns if \"unnamed: 0\" in col] ]\n",
    "df['variable'] = df['variable'].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8').str.lower().str.strip()\n",
    "\n",
    "df['variable'] = df['variable'].str.replace(r'\\(.*?\\)', '', regex=True).str.strip()\n",
    "df.dropna(subset='variable', inplace=True)\n",
    "\n",
    "df['variable'] = df['variable'].str.replace( r'[.\\d]+' , '', regex=True).str.strip()\n",
    "df['variable'] = df['variable'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
    "\n",
    "df.drop([ col for col in df.columns if \"unnamed\" in col ], axis=1, inplace=True)\n",
    "\n",
    "modified_values = []\n",
    "for i, row in df.iterrows():\n",
    "    if \"cartera\" in row['variable'].lower():\n",
    "        modified_value = f\"{row['variable']} - {df.at[i-1, 'variable']}\"\n",
    "        modified_values.append(modified_value)\n",
    "    else:\n",
    "        modified_values.append(row['variable'])\n",
    "\n",
    "df['variable'] = modified_values\n",
    "\n",
    "\n",
    "df = pd.melt(df, id_vars='variable', var_name='date', value_name='value')\n",
    "\n",
    "months = {'enero': '01', 'febrero': '02', 'marzo':'03', 'abril':'04', 'mayo': '05', 'junio': '06','julio': '07','agosto': '08','septiembre': '09','octubre': '10','noviembre': '11','diciembre': '12', \n",
    "          'ene': '01', 'feb': '02', 'mar':'03', 'abr':'04', 'may': '05', 'jun': '06','jul': '07','ago': '08','sep': '09','oct': '10','nov': '11','dic': '12','dec': '12' }\n",
    "\n",
    "df['date'] = df['date'].astype(str).str.lower().replace(months, regex=True)\n",
    "df['date'] = df['date'].str.replace('_', '-')\n",
    "\n",
    "\n",
    "def remove_repeated_year(date_str):\n",
    "    # Match the format 'YYYY-YYYY-rest' or 'YYYY-rest'\n",
    "    match = re.match(r'(\\d{4})-(\\d{4})-(.*)', date_str)\n",
    "    if match and match.group(1) == match.group(2):\n",
    "        return f\"{match.group(1)}-{match.group(3)}\"\n",
    "    return date_str\n",
    "df['date'] = df['date'].apply(remove_repeated_year)\n",
    "df['date'] = df['date'].replace(r'^(\\d{4}-\\d{2})$', r'\\1-01', regex=True)\n",
    "\n",
    "def parse_date(date_str):\n",
    "    try:\n",
    "        return pd.to_datetime(date_str, format='%Y-%m-%d %H:%M:%S')\n",
    "    except ValueError:\n",
    "        try:\n",
    "            return pd.to_datetime(date_str, format='%Y-%m-%d')\n",
    "        except ValueError:\n",
    "            return pd.NaT\n",
    "df['date'] = df['date'].apply(parse_date)\n",
    "df.date = pd.to_datetime(df.date)\n",
    "df.set_index('date', inplace=True)\n",
    "\n",
    "df.dropna(subset='value', inplace=True)\n",
    "df = df[df['variable'].str.contains('cartera') ]\n",
    "\n",
    "df = df.pivot(columns='variable', values='value')\n",
    "df.rename( columns=lambda x: f\"{x.replace(' - ', '_')}\" , inplace=True)\n",
    "\n",
    "df = pd.DataFrame(df.resample(\"MS\").last()).sort_index()\n",
    "df.to_csv(f\"{PATH_RAW}/bce_ims14.csv\")\n",
    "print(f\"Cartera updated: {df.index.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff6d17d-31cf-4726-aa5e-c69225846f80",
   "metadata": {},
   "source": [
    "**Balanza de Pagos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649c3466-b6ed-4c4c-ae3d-547758924062",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://contenido.bce.fin.ec/documentos/Estadisticas/SectorExterno/BalanzaPagos/indice.htm\"\n",
    "\n",
    "r = requests.get(url, headers=hdr, verify=False)\n",
    "r = r.content\n",
    "\n",
    "soup = BeautifulSoup(r, 'html.parser')\n",
    "links = soup.find_all('a')\n",
    "\n",
    "links = [ link.get('href') for link in links if \"htm\" in link.get('href') ]\n",
    "def get_boletin_number(url):\n",
    "    return int(url.split('boletin')[-1].split('/')[0])\n",
    "    \n",
    "links = max(links, key=get_boletin_number)\n",
    "\n",
    "r = requests.get(links, headers=hdr, verify=False)\n",
    "r = r.content\n",
    "\n",
    "soup = BeautifulSoup(r, 'html.parser')\n",
    "links = soup.find_all('a')\n",
    "\n",
    "get = [ link.get('href') for link in links if \"bp\" in link.get('href').lower() ]\n",
    "\n",
    "df = pd.ExcelFile( BytesIO(requests.get(get[0], headers=hdr, verify=False).content) )\n",
    "df = pd.read_excel(df, skiprows=7, skipfooter=5)\n",
    "\n",
    "df.columns = df.columns.astype(\"str\").str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8').str.lower().str.strip()\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "df = df[ ( df['componentes normalizados'].str.contains('CUENTA') & ~df['componentes normalizados'].str.lower().str.contains('otras')) | df['componentes normalizados'].str.contains('ACTIVOS DE RESERVA') | df['componentes normalizados'].str.lower().str.contains('ingreso primario') | df['componentes normalizados'].str.lower().str.contains('ingreso secundario') | ( df['componentes normalizados'] == ('SERVICIOS')) | ( df['componentes normalizados'] == ('BIENES Y SERVICIOS')) ]\n",
    "df['componentes normalizados'] = df['componentes normalizados'].astype(\"str\").str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8').str.lower().str.strip()\n",
    "df = pd.melt(df, id_vars=\"componentes normalizados\", var_name=\"date\")\n",
    "df = df[df['date'].str.contains(\"i\")]\n",
    "\n",
    "quarter_mapping = {\n",
    "    'iv': 'Q4',\n",
    "    'iii': 'Q3',\n",
    "    'ii': 'Q2',\n",
    "    'i': 'Q1',    \n",
    "}\n",
    "\n",
    "for roman, quarter in quarter_mapping.items():\n",
    "    df['date'] = df['date'].str.replace(roman, quarter)\n",
    "    \n",
    "def quarter_to_date(quarter):\n",
    "    q, year = quarter.split('-')\n",
    "    month = {'Q1': '01', 'Q2': '04', 'Q3': '07', 'Q4': '10'}[q]\n",
    "    return pd.to_datetime(f\"{year}-{month}-01\")\n",
    "\n",
    "df['date'] = df['date'].apply(quarter_to_date)\n",
    "df.set_index('date' , inplace=True)\n",
    "\n",
    "df = pd.pivot(df, columns=\"componentes normalizados\", values=\"value\")\n",
    "df.rename(columns = { 'bienes y servicios' : 'balanza comercial' } , inplace=True)\n",
    "df.to_csv(f\"{PATH_RAW}/bce_bp.csv\")\n",
    "print(f\"BP updated: {df.index.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6e5fdd-9381-437d-84fa-255a79e3d94b",
   "metadata": {},
   "source": [
    "**Balanza Comercial**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7f933e-de79-4624-9a03-01794727cbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://contenido.bce.fin.ec/documentos/PublicacionesNotas/Catalogo/IEMensual/Indices/m2068062024.html\"\n",
    "r = requests.get(url, headers=hdr, verify=False)\n",
    "r = r.content\n",
    "\n",
    "soup = BeautifulSoup(r, 'html.parser')\n",
    "links = soup.find_all('a')\n",
    "\n",
    "get = [ link.get('href') for link in links if \"322-e\" in link.get('href') ]\n",
    "\n",
    "df = pd.read_excel( BytesIO(requests.get(get[0], headers=hdr, verify=False).content) , skiprows=7, header=[0,1], skipfooter=2)\n",
    "df.columns = df.columns.map('{0[0]}_{0[1]}'.format)\n",
    "df.columns = df.columns.astype(\"str\").str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8').str.lower().str.strip()\n",
    "\n",
    "df.rename( columns=lambda x: \"month\" if \"periodo\" in x else x, inplace=True )\n",
    "df = df[[ col for col in df.columns if \"month\" in col or col.startswith(\"exportaciones\")  or col.startswith(\"importaciones\") or col.startswith(\"balanza\") ]]\n",
    "\n",
    "df.rename( columns=lambda x: f\"{x.replace('_', ' ')}\" , inplace=True)\n",
    "\n",
    "df.dropna(subset='month', inplace=True)\n",
    "df.columns = df.columns.str.replace(r'\\(.*?\\)', '', regex=True).str.strip().str.replace('  ', ' ')\n",
    "df = df[df['month'].str.isnumeric()==False]\n",
    "df['year'] = df['month'].str.extract(r'(\\d+)').ffill()\n",
    "df = df[~df['month'].str.contains(r'\\d')]\n",
    "months = {'enero': '01', 'febrero': '02', 'marzo':'03', 'abril':'04', 'mayo': '05', 'junio': '06','julio': '07','agosto': '08','septiembre': '09','octubre': '10','noviembre': '11','diciembre': '12', \n",
    "          'ene': '01', 'feb': '02', 'mar':'03', 'abr':'04', 'may': '05', 'jun': '06','jul': '07','ago': '08','sep': '09','oct': '10','nov': '11','dic': '12','dec': '12' }\n",
    "\n",
    "df['month'] = df['month'].astype(str).str.lower().replace(months, regex=True)\n",
    "df[\"date\"] = pd.to_datetime(df[['year', 'month']].assign(DAY=1), format='%b')\n",
    "\n",
    "df = df[[ col for col in df.columns if \"date\" in col or col.startswith(\"exportaciones\")  or col.startswith(\"importaciones\") or col.startswith(\"balanza\") ]]\n",
    "df.set_index('date', inplace = True)\n",
    "df.to_csv(f\"{PATH_RAW}/bce_bc.csv\")\n",
    "\n",
    "print(f\"Balanza Comercial updated: {df.index.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a64c02-cb0c-4eb2-8b38-e2f4d365c34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "get = [ link.get('href') for link in links if \"312-e\" in link.get('href') ]\n",
    "df = pd.read_excel( BytesIO(requests.get(get[0], headers=hdr, verify=False).content) , skiprows=7, header=[0,1,2], skipfooter=2)\n",
    "df.columns = df.columns.map('{0[0]}_{0[1]}_{0[2]}'.format)\n",
    "df.columns = df.columns.astype(\"str\").str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8').str.lower().str.strip()\n",
    "df.rename( columns=lambda x: \"year\" if \"periodo\" in x and \"0_\" in x else x, inplace=True )\n",
    "df.rename( columns=lambda x: \"month\" if \"periodo\" in x and \"1_\" in x else x, inplace=True )\n",
    "\n",
    "df.dropna(subset='month', inplace=True)\n",
    "df['year'] = df['year'].ffill().astype(int)\n",
    "df = df[~df['month'].str.contains(\"-\")]\n",
    "\n",
    "df.columns = df.columns.str.replace(r'\\(.*?\\)', '', regex=True).str.strip().str.replace('  ', ' ')\n",
    "months = {'enero': '01', 'febrero': '02', 'marzo':'03', 'abril':'04', 'mayo': '05', 'junio': '06','julio': '07','agosto': '08','septiembre': '09','octubre': '10','noviembre': '11','diciembre': '12', \n",
    "          'ene': '01', 'feb': '02', 'mar':'03', 'abr':'04', 'may': '05', 'jun': '06','jul': '07','ago': '08','sep': '09','oct': '10','nov': '11','dic': '12','dec': '12' }\n",
    "\n",
    "df['month'] = df['month'].astype(str).str.lower().replace(months, regex=True)\n",
    "df[\"date\"] = pd.to_datetime(df[['year', 'month']].assign(DAY=1), format='%b')\n",
    "df.drop(['year', 'month'], axis=1, inplace=True)\n",
    "df.set_index('date', inplace=True)\n",
    "df.columns = df.columns.astype('str').str.replace('_unnamed:',' ').str.replace(r'(\\d+_level_\\d+)',' ', regex=True)\n",
    "df.columns = df.columns.astype('str').str.replace('_',' ').str.replace('  ',' ')\n",
    "df.rename( columns=lambda x: f\"exportaciones {x}\" if \"exportaciones\" not in x else x , inplace = True )\n",
    "\n",
    "df.to_csv(f\"{PATH_RAW}/bce_exports.csv\")\n",
    "print(f\"Exportaciones updated: {df.index.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58b4cbc-87a0-4e8c-8e86-09ed95f3ac2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "get = [ link.get('href') for link in links if \"316-e\" in link.get('href') ]\n",
    "\n",
    "df = pd.read_excel( BytesIO(requests.get(get[0], headers=hdr, verify=False).content) , skiprows=7, header=[0,1], skipfooter=2)\n",
    "df.columns = df.columns.map('{0[0]}_{0[1]}'.format)\n",
    "df.columns = df.columns.astype(\"str\").str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8').str.lower().str.strip()\n",
    "df.rename( columns=lambda x: \"year\" if \"periodo\" in x and \"0_\" in x else x, inplace=True )\n",
    "df.rename( columns=lambda x: \"month\" if \"periodo\" in x and \"1_\" in x else x, inplace=True )\n",
    "\n",
    "df.dropna(subset='month', inplace=True)\n",
    "df['year'] = df['year'].ffill().astype(int)\n",
    "df = df[~df['month'].str.contains(\"-\")]\n",
    "\n",
    "df.columns = df.columns.str.replace(r'\\(.*?\\)', '', regex=True).str.strip().str.replace('  ', ' ')\n",
    "months = {'enero': '01', 'febrero': '02', 'marzo':'03', 'abril':'04', 'mayo': '05', 'junio': '06','julio': '07','agosto': '08','septiembre': '09','octubre': '10','noviembre': '11','diciembre': '12', \n",
    "          'ene': '01', 'feb': '02', 'mar':'03', 'abr':'04', 'may': '05', 'jun': '06','jul': '07','ago': '08','sep': '09','oct': '10','nov': '11','dic': '12','dec': '12' }\n",
    "\n",
    "df['month'] = df['month'].astype(str).str.lower().replace(months, regex=True)\n",
    "df[\"date\"] = pd.to_datetime(df[['year', 'month']].assign(DAY=1), format='%b')\n",
    "df.drop(['year', 'month'], axis=1, inplace=True)\n",
    "df.set_index('date', inplace=True)\n",
    "\n",
    "df.columns = df.columns.astype('str').str.replace('_unnamed:',' ').str.replace(r'(\\d+_level_\\d+)',' ', regex=True)\n",
    "df.columns = df.columns.astype('str').str.replace('_',' ').str.replace('  ',' ')\n",
    "df.rename( columns=lambda x: f\"importaciones {x}\" if \"importaciones\" not in x else x , inplace = True )\n",
    "\n",
    "df.to_csv(f\"{PATH_RAW}/bce_imports.csv\")\n",
    "print(f\"Importaciones updated: {df.index.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db23c007-a811-491f-8cf2-fbf07b961d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "get = [ link.get('href') for link in links if \"341-e\" in link.get('href') ]\n",
    "\n",
    "df = pd.read_excel( BytesIO(requests.get(get[0], headers=hdr, verify=False).content) , skiprows=7, header=[0,1], skipfooter=2)\n",
    "df.columns = df.columns.map('{0[0]}_{0[1]}'.format)\n",
    "df.columns = df.columns.astype(\"str\").str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8').str.lower().str.strip()\n",
    "df.rename( columns=lambda x: \"date\" if \"periodo\" in x else x, inplace=True )\n",
    "df.dropna(subset='date', inplace=True)\n",
    "\n",
    "# Extract Year\n",
    "df['year'] = df['date'].str.extract(r'(\\d{4})')\n",
    "df['year'] = df['year'].ffill()\n",
    "df.dropna(subset='year', inplace=True)\n",
    "\n",
    "df['month'] = df['date'].str.replace(r'\\d{4} ', '', regex=True)\n",
    "months = {'enero': '01', 'febrero': '02', 'marzo':'03', 'abril':'04', 'mayo': '05', 'junio': '06','julio': '07','agosto': '08','septiembre': '09','octubre': '10','noviembre': '11','diciembre': '12', \n",
    "          'ene': '01', 'feb': '02', 'mar':'03', 'abr':'04', 'may': '05', 'jun': '06','jul': '07','ago': '08','sep': '09','oct': '10','nov': '11','dic': '12','dec': '12' }\n",
    "\n",
    "df['month'] = df['month'].astype(str).str.lower().replace(months, regex=True)\n",
    "df[\"date\"] = pd.to_datetime(df[['year', 'month']].assign(DAY=1), format='%b')\n",
    "df.drop(['year', 'month'], axis=1, inplace=True)\n",
    "df.set_index('date', inplace=True)\n",
    "\n",
    "df.columns = df.columns.astype('str').str.replace(r'\\(.*?\\)', '', regex=True).str.strip()\n",
    "df.columns = df.columns.astype('str').str.replace('_unnamed:',' ').str.replace(r'(\\d+_level_\\d+)',' ', regex=True)\n",
    "df.columns = df.columns.astype('str').str.replace('_',' ').str.replace('  ',' ')\n",
    "df.rename( columns=lambda x: f\"tdc {x}\" if \"date\" not in x else x , inplace = True )\n",
    "\n",
    "df.to_csv(f\"{PATH_RAW}/bce_tdc.csv\")\n",
    "print(f\"Tipo de Cambio updated: {df.index.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75dc8d5-9c8e-42a8-8235-f31785f787d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "get = [ link.get('href') for link in links if \"342-e\" in link.get('href') ]\n",
    "\n",
    "df = pd.read_excel( BytesIO(requests.get(get[0], headers=hdr, verify=False).content) , skiprows=7, header=[0,1], skipfooter=2)\n",
    "df.columns = df.columns.map('{0[0]}_{0[1]}'.format)\n",
    "df.columns = df.columns.astype(\"str\").str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8').str.lower().str.strip()\n",
    "\n",
    "df.rename( columns=lambda x: \"date\" if \"periodo\" in x else x, inplace=True )\n",
    "df.dropna(subset='date', inplace=True)\n",
    "\n",
    "# Extract Year\n",
    "df['year'] = df['date'].str.extract(r'(\\d{4})')\n",
    "df['year'] = df['year'].ffill()\n",
    "df.dropna(subset='year', inplace=True)\n",
    "\n",
    "df['month'] = df['date'].str.replace(r'\\d{4} ', '', regex=True)\n",
    "months = {'enero': '01', 'febrero': '02', 'marzo':'03', 'abril':'04', 'mayo': '05', 'junio': '06','julio': '07','agosto': '08','septiembre': '09','octubre': '10','noviembre': '11','diciembre': '12', \n",
    "          'ene': '01', 'feb': '02', 'mar':'03', 'abr':'04', 'may': '05', 'jun': '06','jul': '07','ago': '08','sep': '09','oct': '10','nov': '11','dic': '12','dec': '12' }\n",
    "\n",
    "df['month'] = df['month'].astype(str).str.lower().replace(months, regex=True)\n",
    "df[\"date\"] = pd.to_datetime(df[['year', 'month']].assign(DAY=1), format='%b')\n",
    "df.drop(['year', 'month'], axis=1, inplace=True)\n",
    "df.set_index('date', inplace=True)\n",
    "\n",
    "df.columns = df.columns.astype('str').str.replace('_unnamed:',' ').str.replace(r'(\\d+_level_\\d+)',' ', regex=True)\n",
    "df.columns = df.columns.astype('str').str.replace('_',' ').str.replace('  ',' ')\n",
    "df.columns = df.columns.astype('str').str.replace(r'\\(\\d?\\)', '', regex=True).str.strip()\n",
    "df.columns = df.columns.astype('str').str.replace(r'[()]', '', regex=True).str.strip()\n",
    "df.rename( columns=lambda x: f\"tdc_usd {x}\" if \"date\" not in x else x , inplace = True )\n",
    "\n",
    "df.to_csv(f\"{PATH_RAW}/bce_tdc_usd.csv\")\n",
    "print(f\"Tipo de Cambio updated: {df.index.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88c92ba-284a-4865-bf0a-5a452467cb7d",
   "metadata": {},
   "source": [
    "**Indice de Precios de la Construccion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c154027-40b2-4d37-a671-e4b2048be918",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.ecuadorencifras.gob.ec/indice-de-precios-de-la-construccion/\"\n",
    "r = requests.get(url=url, verify=False).content\n",
    "\n",
    "soup = BeautifulSoup(r, 'html.parser')\n",
    "links = soup.find_all('a')\n",
    "\n",
    "excel_links = [ link.get('href') for link in links if \n",
    "               link.get('href') is not None and\n",
    "               \"tab\" in link.get('href').lower() and\n",
    "               \"excel\" in link.get('href').lower() \n",
    "              ]\n",
    "\n",
    "file = zipfile.ZipFile((io.BytesIO( urlopen(excel_links[0]).read() )))\n",
    "f = [ f for f in file.namelist() if \"xlsx\" in f and \"historica\" in f and \"general\" in f]\n",
    "\n",
    "if len(f)==1: \n",
    "    df = pd.ExcelFile(file.open(f[0]).read())\n",
    "    sheets = [ '1. ndice' ]\n",
    "    dfi = pd.read_excel( df, sheet_name=sheets[0] , skiprows=4 )\n",
    "    dfi.columns = dfi.columns.astype(\"str\").str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8').str.lower().str.strip()\n",
    "    dfi = dfi[[ col for col in dfi.columns if \"unnamed\" not in col ]]\n",
    "    dfi.rename(columns = {'anos' : 'year'} , inplace=True)\n",
    "    dfi = pd.melt( dfi , id_vars = \"year\" , var_name = 'month' )\n",
    "\n",
    "    months = {'enero': '01', 'febrero': '02', 'marzo':'03', 'abril':'04', 'mayo': '05', 'junio': '06','julio': '07','agosto': '08','septiembre': '09','octubre': '10','noviembre': '11','diciembre': '12', \n",
    "              'ene': '01', 'feb': '02', 'mar':'03', 'abr':'04', 'may': '05', 'jun': '06','jul': '07','ago': '08','sep': '09','oct': '10','nov': '11','dic': '12','dec': '12' }\n",
    "    dfi['month'] = dfi['month'].astype(str).str.lower().replace(months, regex=True)\n",
    "\n",
    "    dfi[\"date\"] = pd.to_datetime(dfi[['year', 'month']].assign(DAY=1), format='%b')\n",
    "    dfi = dfi[['value', 'date']]\n",
    "    dfi.set_index('date', inplace=True)\n",
    "    dfi.rename( columns = { 'value' : 'IPCO' } , inplace=True)\n",
    "    dfi = dfi.dropna().sort_index()\n",
    "    dfi.IPCO = dfi.IPCO.astype('str').str.replace(',','.')\n",
    "    dfi['IPCO'] = pd.to_numeric(dfi['IPCO'].replace(r'[^0-9.]', '', regex=True))\n",
    "    \n",
    "    dfi.to_csv(f\"{PATH_RAW}/bce_ipco.csv\")\n",
    "    print(f\"Indice de Precios de la Construccion updated: {dfi.index.max()}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0a2cca7b-68ba-47ad-9f27-c4b25e3fd326",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "if len(f)==1: \n",
    "    df = pd.ExcelFile(file.open(f[0]).read())\n",
    "    sheets = [ '1. ndices materiales' ]\n",
    "    dfi = pd.read_excel( df, sheet_name=sheets[0] , skiprows=4 , skipfooter=2)\n",
    "    dfi.columns = dfi.columns.astype(\"str\").str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8').str.lower().str.strip()\n",
    "    dfi = dfi[[ col for col in dfi.columns if \"unnamed\" not in col ]]\n",
    "    dfi['denominacion'] = dfi['denominacion'].astype(\"str\").str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8').str.lower().str.strip()\n",
    "    dfi = pd.melt( dfi , id_vars = \"denominacion\" , var_name = 'date' )\n",
    "\n",
    "    dfi['date'] = dfi['date'].astype('str').str.replace('/','-20')\n",
    "    \n",
    "    months = {'enero': '01', 'febrero': '02', 'marzo':'03', 'abril':'04', 'mayo': '05', 'junio': '06','julio': '07','agosto': '08','septiembre': '09','octubre': '10','noviembre': '11','diciembre': '12', \n",
    "          'ene': '01', 'feb': '02', 'mar':'03', 'abr':'04', 'may': '05', 'jun': '06','jul': '07','ago': '08','sep': '09','oct': '10','nov': '11','dic': '12','dec': '12' }\n",
    "    dfi['date'] = dfi['date'].astype(str).str.lower().replace(months, regex=True)\n",
    "    dfi['date'] = \"01-\" + dfi['date']\n",
    "    dfi['date'] = pd.to_datetime(dfi['date'] , format = \"%d-%m-%Y\")\n",
    "    dfi.set_index('date', inplace=True)\n",
    "\n",
    "    dfi.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efdeaa1-eef3-408a-b2ef-c5d73c3bd8ac",
   "metadata": {},
   "source": [
    "**Indice de Situacion Presente**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ea4313-b5fe-4cb4-8af3-0d184f603943",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://contenido.bce.fin.ec/documentos/PublicacionesNotas/Catalogo/IEMensual/Indices/m2068062024.html\"\n",
    "r = requests.get(url=url, verify=False).content\n",
    "soup = BeautifulSoup(r, 'html.parser')\n",
    "links = soup.find_all('a')\n",
    "\n",
    "get = [ link.get('href') for link in links if link.get('href') is not None and \"462-e\" in link.get('href') ]\n",
    "\n",
    "df = pd.read_excel( BytesIO(requests.get(get[0], headers=hdr, verify=False).content) , skiprows=7, header=[0,1], skipfooter=2)\n",
    "df.columns = df.columns.map('{0[0]}_{0[1]}'.format)\n",
    "df.columns = df.columns.astype(\"str\").str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8').str.lower().str.strip()\n",
    "\n",
    "df.rename( columns=lambda x: \"year\" if \"periodo\" in x and \"0_level\" in x else x, inplace=True )\n",
    "df.rename( columns=lambda x: \"month\" if \"periodo\" in x and \"1_level\" in x else x, inplace=True )\n",
    "\n",
    "df.dropna(subset='month', inplace=True)\n",
    "df['month'] = df['month'].astype(\"str\").str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8').str.lower().str.strip()\n",
    "\n",
    "df.loc[df[df['month'] == 'enero'].last_valid_index(), 'year']  = datetime.now().year\n",
    "df['year'] = df['year'].ffill()\n",
    "df.dropna(subset='month', inplace=True)\n",
    "df['month'] = df['month'].str.replace(r'\\(.*?\\)', '', regex=True).str.strip()\n",
    "months = {'enero': '01', 'febrero': '02', 'marzo':'03', 'abril':'04', 'mayo': '05', 'junio': '06','julio': '07','agosto': '08','septiembre': '09','octubre': '10','noviembre': '11','diciembre': '12', \n",
    "          'ene': '01', 'feb': '02', 'mar':'03', 'abr':'04', 'may': '05', 'jun': '06','jul': '07','ago': '08','sep': '09','oct': '10','nov': '11','dic': '12','dec': '12' }\n",
    "df['month'] = df['month'].astype(str).str.lower().replace(months, regex=True)\n",
    "df[\"date\"] = pd.to_datetime(df[['year', 'month']].assign(DAY=1), format='%b')\n",
    "df.set_index('date', inplace=True)\n",
    "\n",
    "\n",
    "df.columns = df.columns.str.replace(r'\\(.*?\\)', '', regex=True).str.strip()\n",
    "df.drop(['year', 'month'], axis=1, inplace=True)\n",
    "df.columns = df.columns.astype(str).str.replace(\"_\" , \" \")\n",
    "\n",
    "df.to_csv(f\"{PATH_RAW}/bce_situacion.csv\")\n",
    "print(f\"Indice de Situacion Presente: {df.index.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29687da-466c-4872-8618-781da33b81f3",
   "metadata": {},
   "source": [
    "## Banco de Peru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14882f62-10b0-4de0-8c31-9bee36834c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get = \"https://estadisticas.bcrp.gob.pe/estadisticas/series/api/\"\n",
    "today = date.today().year + 1\n",
    "\n",
    "variables = {\n",
    "    \"PD04712XD\" : \"bcrp_embig\" ,\n",
    "    \"PN01134XM\" : \"bcrp_embigdiff\" ,\n",
    "}\n",
    "\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "months = {'enero': '01', 'febrero': '02', 'marzo':'03', 'abril':'04', 'mayo': '05', 'junio': '06','julio': '07','agosto': '08','septiembre': '09','octubre': '10','noviembre': '11','diciembre': '12', \n",
    "      'ene': '01', 'feb': '02', 'mar':'03', 'abr':'04', 'may': '05', 'jun': '06','jul': '07','ago': '08','sep': '09','set': '09','oct': '10','nov': '11','dic': '12','dec': '12' }\n",
    "\n",
    "for k, v in variables.items() :\n",
    "    url = f\"https://estadisticas.bcrp.gob.pe/estadisticas/series/api/{k}/json/1980-01-01/{today}-01-01\"\n",
    "    resp = requests.get(url)\n",
    "    data = resp.json()\n",
    "    dfi = pd.DataFrame(data['periods'] )\n",
    "    \n",
    "    dfi.rename(columns = { 'name' : 'date', 'values' : v }, inplace=True)\n",
    "    dfi[v] = pd.to_numeric(dfi[v].astype(str).str.extract('(\\d+.\\d+)', expand=False) )\n",
    "    \n",
    "    \n",
    "    dfi['date'] = dfi['date'].astype(str).str.lower().replace(months, regex=True)\n",
    "    dfi['date'] = dfi['date'].astype(str).str.replace(\".\", \"-\")\n",
    "    if v == \"bcrp_embigdiff\" :\n",
    "        dfi.date = pd.to_datetime(dfi.date, format = \"%m-%Y\")\n",
    "    else :\n",
    "        dfi.date = pd.to_datetime(dfi.date, format = \"%d-%m-%y\")\n",
    "    dfi.set_index('date' , inplace=True)\n",
    "    \n",
    "    df = df.merge(dfi, left_index=True, right_index=True, how='outer')\n",
    "\n",
    "df.to_csv(f\"{PATH_RAW}/bcrp_embig.csv\")\n",
    "print(f\"EMBIG: {df.index.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89255447-fa70-4b07-afb2-5cc0502e66a2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Federal Reserve FRED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a80b70-4c04-4d6f-aef6-5ea357233fa0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "series = [\"DCOILWTICO\", \"WUIECU\", \"IMP3310\", \"EXP3310\", \"CPIAUCSL\"]\n",
    "\n",
    "api_key = \"6082258bcc5fa73a032d9d60c890f744\"\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for serie in series :\n",
    "\n",
    "    url = f\"https://api.stlouisfed.org/fred/series/observations?series_id={serie}&realtime_end=9999-12-31&api_key={api_key}&file_type=json\"\n",
    "    response = requests.get(url)\n",
    "    response = response.json()\n",
    "    dfi = pd.DataFrame(response['observations'])\n",
    "    dfi = dfi[['value', 'date']]\n",
    "    dfi.set_index('date', inplace=True)\n",
    "    dfi.index = pd.to_datetime(dfi.index)\n",
    "    dfi.rename(columns = { \"value\" : f\"fred_{serie}\" }, inplace=True)\n",
    "    dfi[f\"fred_{serie}\"] = dfi[f\"fred_{serie}\"].apply(pd.to_numeric, errors='coerce')\n",
    "    df = df.merge(dfi, left_index=True, right_index=True, how='outer')\n",
    "    df = pd.DataFrame(df.resample(\"D\").mean())\n",
    "    #df = pd.concat([df, dfi], axis=1)\n",
    "    df.sort_index(inplace=True)\n",
    "    \n",
    "df.to_csv(f\"{PATH_RAW}/fred_data.csv\")\n",
    "print(f\"FRED Updated: {df.index.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f5387d-e721-44af-b6a9-1ae97d0d1fe9",
   "metadata": {},
   "source": [
    "## Inflacion en paises seleccionados\n",
    "- EEUU\n",
    "- China\n",
    "- Colombia\n",
    "- Peru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd277bd3-6209-49e2-8ce4-62d6c8957237",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "series = [ \"CPIAUCSL\" , \"CHNCPIALLMINMEI\" ]\n",
    "api_key = \"6082258bcc5fa73a032d9d60c890f744\"\n",
    "\n",
    "for serie in series :\n",
    "    url = f\"https://api.stlouisfed.org/fred/series/observations?series_id={serie}&observation_start=1990-01-01&realtime_start={datetime.today().strftime('%Y-%m-%d')}&realtime_end=9999-12-31&api_key={api_key}&file_type=json\"\n",
    "    response = requests.get(url)\n",
    "    response = response.json()\n",
    "    dfi = pd.DataFrame(response['observations'])\n",
    "    dfi = dfi[['value', 'date']]\n",
    "    dfi.rename(columns = { \"value\" : f\"{serie}\" }, inplace=True)\n",
    "    dfi[serie] = pd.to_numeric(dfi[serie], errors='coerce')\n",
    "    dfi.dropna(inplace=True)\n",
    "    dfi.set_index('date', inplace=True)\n",
    "    dfi.index = pd.to_datetime(dfi.index)\n",
    "    dfi.sort_index(inplace=True)\n",
    "    dfi = dfi[~dfi.index.duplicated(keep='first')]\n",
    "    df = df.merge(dfi, left_index=True, right_index=True, how='outer')\n",
    "\n",
    "df.rename(columns = { \"CPIAUCSL\" : f\"CPI EEUU\" , \"CHNCPIALLMINMEI\" : \"CPI CN\" }, inplace=True)\n",
    "df.to_csv(f\"{PATH_RAW}/international_data.csv\")\n",
    "print(f\"Inflacion 1 Updated: {df.index.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6d0d53-f739-4ef3-ab59-a423ca108f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.dane.gov.co/index.php/estadisticas-por-tema/precios-y-costos/indice-de-precios-al-consumidor-ipc\"\n",
    "r = requests.get(url, headers=hdr, verify=False)\n",
    "r = r.content\n",
    "\n",
    "soup = BeautifulSoup(r, 'html.parser')\n",
    "links = soup.find_all('a')\n",
    "\n",
    "get = [ link.get('href') for link in links if link.get('href') is not None and \"Indices\" in link.get('href') ]\n",
    "get = f\"https://www.dane.gov.co/{get[0]}\"\n",
    "dfi = pd.read_excel( get , skiprows=8, skipfooter=3)\n",
    "\n",
    "dfi = pd.melt( dfi , id_vars = \"Mes\" , var_name = 'year' )\n",
    "dfi.rename( columns = { \"Mes\" : \"month\" , \"value\" : \"CPI CO\" } , inplace=True)\n",
    "dfi.dropna( subset= \"CPI CO\" , inplace = True)\n",
    "\n",
    "months = {'enero': '01', 'febrero': '02', 'marzo':'03', 'abril':'04', 'mayo': '05', 'junio': '06','julio': '07','agosto': '08','septiembre': '09','octubre': '10','noviembre': '11','diciembre': '12', \n",
    "          'ene': '01', 'feb': '02', 'mar':'03', 'abr':'04', 'may': '05', 'jun': '06','jul': '07','ago': '08','sep': '09','oct': '10','nov': '11','dic': '12','dec': '12' }\n",
    "\n",
    "dfi['month'] = dfi['month'].astype(str).str.lower().replace(months, regex=True)\n",
    "dfi[\"date\"] = pd.to_datetime(dfi[['year', 'month']].assign(DAY=1), format='%b')\n",
    "\n",
    "dfi = dfi[[ 'CPI CO' , 'date' ]].set_index('date')\n",
    "df = df.merge(dfi, left_index=True, right_index=True, how='outer')\n",
    "df.to_csv(f\"{PATH_RAW}/international_data.csv\")\n",
    "print(f\"Inflacion 2 Updated: {df.index.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ded30bd-6912-4282-862c-7084c6d9c927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get = \"https://estadisticas.bcrp.gob.pe/estadisticas/series/api/\"\n",
    "today = date.today().year + 1\n",
    "\n",
    "url = f\"https://estadisticas.bcrp.gob.pe/estadisticas/series/api/PN38705PM/json/1980-01-01/{today}-01-01\"\n",
    "resp = requests.get(url)\n",
    "data = resp.json()\n",
    "dfi = pd.DataFrame(data['periods'] )\n",
    "dfi.rename(columns = { 'name' : 'date', 'values' : \"CPI PE\" }, inplace=True)\n",
    "dfi['CPI PE'] = pd.to_numeric(dfi['CPI PE'].astype(str).str.extract('(\\d+.\\d+)', expand=False) )\n",
    "\n",
    "dfi[\"date\"] = dfi[\"date\"].astype(str).str.lower().replace(months, regex=True)\n",
    "dfi['date'] = dfi['date'].astype(str).str.replace(r'(\\d{2}).(\\d{4})', r\"\\2-\\1-01\", regex=True)\n",
    "dfi.date = pd.to_datetime(dfi.date)\n",
    "dfi.set_index('date' , inplace=True)\n",
    "\n",
    "df = df.merge(dfi, left_index=True, right_index=True, how='outer')\n",
    "df.to_csv(f\"{PATH_RAW}/international_data.csv\")\n",
    "print(f\"Inflacion 3 Updated: {df.index.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a5cbd3-9405-498a-858a-7f198e36f411",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Servicio de Rentas Internas\n",
    "\n",
    "- VAT\n",
    "- Ventas\n",
    "- Vehiculos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389e047b-9270-41f7-a92d-b0ec781e21a7",
   "metadata": {},
   "source": [
    "**Estadisticas de Recaudacion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a91433-6620-4074-afc6-9bccbe89c54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.sri.gob.ec/estadisticas-generales-de-recaudacion-sri\"\n",
    "r = requests.get(url, headers=hdr, verify=False)\n",
    "r = r.content\n",
    "\n",
    "soup = BeautifulSoup(r, 'html.parser')\n",
    "links = soup.find_all('a')\n",
    "\n",
    "months = {'enero': '01', 'febrero': '02', 'marzo':'03', 'abril':'04', 'mayo': '05', 'junio': '06','julio': '07','agosto': '08','septiembre': '09','octubre': '10','noviembre': '11','diciembre': '12', \n",
    "          'ene': '01', 'feb': '02', 'mar':'03', 'abr':'04', 'may': '05', 'jun': '06','jul': '07','ago': '08','sep': '09','oct': '10','nov': '11','dic': '12','dec': '12' }\n",
    "\n",
    "get = [ link.get('href') for link in links if link.get('href') is not None and \"xlsx\" in link.get('href') and \"recauda\" in link.get('href').lower() and \"estad\" in link.get('href').lower()]\n",
    "if len(get)>0 :\n",
    "    get = get[0]\n",
    "    year = re.findall(r'\\d{4}', get.split(\"/\")[-1])[0]\n",
    "    df = pd.ExcelFile(get)\n",
    "    df = pd.read_excel(\n",
    "        df,\n",
    "        sheet_name= [f for f in df.sheet_names if \"abierta\" in f.lower() ][0] ,\n",
    "        skiprows=5 ,\n",
    "        skipfooter=15 ,\n",
    "    )\n",
    "\n",
    "    df.columns = df.columns.str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8').str.lower()\n",
    "    df['conceptos'] = df['conceptos'].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8').str.lower()\n",
    "    df['conceptos'] = df['conceptos'].str.replace(r'\\(.*?\\)', '', regex=True).str.replace('  ', ' ').str.strip()\n",
    "    df.dropna(subset='conceptos', inplace=True)\n",
    "\n",
    "    df = df[df.index<=df[df['conceptos'].str.startswith(\"otros\")].index[0]]\n",
    "    df['the_index'] = df['conceptos'].index.astype(str)\n",
    "    df['conceptos'] = df['the_index'] + \" sri \" + df['conceptos']\n",
    "    df.drop('the_index', axis=1, inplace=True)\n",
    "    \n",
    "    df = pd.melt(df, id_vars=\"conceptos\", var_name=\"date\").dropna(subset=[ 'conceptos', 'value'] )\n",
    " \n",
    "    df['date'] = df['date'].astype(str).str.lower().replace(months, regex=True)\n",
    "    df = df[df['date'].str.match(r'^\\d+(\\.\\d+)?$')]\n",
    "    #FIND YEAR\n",
    "    df['date'] = f\"{year}-\"+df['date']+\"-01\"\n",
    "    df[\"date\"] = pd.to_datetime( df[\"date\"] , format='%Y-%m-%d')\n",
    "    df.set_index('date' , inplace=True)\n",
    "    \n",
    "    df['value'] = pd.to_numeric(df['value'], errors='coerce')\n",
    "    df.dropna(subset='value', inplace=True)\n",
    "    df = df[df.value!=0]\n",
    "    \n",
    "    df = pd.pivot(df, columns=\"conceptos\", values=\"value\")\n",
    "    \n",
    "    df = df[ sorted(df.columns, key=lambda x: int(x.split()[0])) ]\n",
    "\n",
    "    try :\n",
    "        df0 = pd.read_csv(f\"{PATH_RAW}/sri_recaudacion.csv\", index_col='date', parse_dates=True)\n",
    "        df0 = df0[ df0.index.year != df.index.year.max() ]\n",
    "        df = pd.concat( [df0, df] , axis=0)\n",
    "    except :\n",
    "        df0 = df\n",
    "    \n",
    "    df.to_csv(f\"{PATH_RAW}/sri_recaudacion.csv\")\n",
    "    print(f\"Recaudacion SRI Updated: {df.index.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5622f46d-8382-4dca-ba5a-eded2dd5ebf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.read_csv(f\"{PATH_RAW}/sri_recaudacion.csv\", index_col='date', parse_dates=True)\n",
    "\n",
    "url = \"https://www.sri.gob.ec/historico-estadisticas-generales-de-recaudacion\"\n",
    "r = requests.get(url, headers=hdr, verify=False)\n",
    "r = r.content\n",
    "soup = BeautifulSoup(r, 'html.parser')\n",
    "links = soup.find_all('a')\n",
    "get = [ link.get('href') for link in links if link.get('href') is not None and \"xlsx\" in link.get('href') and \"recauda\" in link.get('href').lower() and \"estad\" in link.get('href').lower()]\n",
    "if 'df0' in locals() :\n",
    "    get = [ g for g in get if int(re.findall(r'\\d{4}', g.split(\"/\")[-1].replace(\"%20\",''))[0]) not in df0.index.year.unique() ]\n",
    "\n",
    "column_names = { col.split(' ', 2)[-1]: col for col in df0.columns }\n",
    "column_names['impuesto a la renta global'] = '1 sri impuesto a la renta recaudado'\n",
    "\n",
    "for i in get :\n",
    "    year = re.findall(r'\\d{4}', i.split(\"/\")[-1].replace(\"%20\",''))[0]\n",
    "    if int(year) in df0.index.year.unique() : continue\n",
    "    print(f\"Updating: {year}\")\n",
    "\n",
    "    if \"xlsx\" in i :\n",
    "        df = pd.ExcelFile(i)\n",
    "    elif \"zip\" in i :\n",
    "        file = zipfile.ZipFile((io.BytesIO(urlopen(get[0]).read())))\n",
    "        f = [s for s in file.namelist() if \"estad\" in s.lower() and \"recaudac\" in s.lower() ]\n",
    "        df = pd.ExcelFile( file.open(f[0]).read() )\n",
    "        \n",
    "    try :\n",
    "        if int(year)==2000 : open = year\n",
    "        else : open = [f for f in df.sheet_names if \"abierta\" in f.lower() or \"abierto\" in f.lower() or \"recaudac\" in f.lower() ][0]\n",
    "        df = pd.read_excel(\n",
    "            df,\n",
    "            sheet_name= open ,\n",
    "            skiprows=5 ,\n",
    "            skipfooter=15 ,\n",
    "        )\n",
    "    except :\n",
    "        print(f\"Not updated: {year}.\")\n",
    "        continue\n",
    "\n",
    "    df.columns = df.columns.str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8').str.lower()\n",
    "    df['conceptos'] = df['conceptos'].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8').str.lower()\n",
    "    df['conceptos'] = df['conceptos'].str.replace(r'\\(.*?\\)', '', regex=True).str.replace('  ', ' ').str.strip()\n",
    "    df.dropna(subset='conceptos', inplace=True)\n",
    "\n",
    "    try :\n",
    "        df = df[df.index<=df[df['conceptos'].str.startswith(\"otros\")].index[0]]\n",
    "    except :\n",
    "        None\n",
    "    df['conceptos'] = df['conceptos'].map(column_names)\n",
    "    \n",
    "    df = pd.melt(df, id_vars=\"conceptos\", var_name=\"date\").dropna(subset=[ 'conceptos', 'value'] )\n",
    " \n",
    "    df['date'] = df['date'].astype(str).str.lower().replace(months, regex=True)\n",
    "    df = df[df['date'].str.match(r'^\\d+(\\.\\d+)?$')]\n",
    "    #FIND YEAR\n",
    "    df['date'] = f\"{year}-\"+df['date']+\"-01\"\n",
    "    df[\"date\"] = pd.to_datetime( df[\"date\"] , format='%Y-%m-%d')\n",
    "    df.set_index('date' , inplace=True)\n",
    "    \n",
    "    df['value'] = pd.to_numeric(df['value'], errors='coerce')\n",
    "    df.dropna(subset='value', inplace=True)\n",
    "    df = df[df.value!=0]\n",
    "    \n",
    "    df = pd.pivot(df, columns=\"conceptos\", values=\"value\")\n",
    "    \n",
    "    df = df[ sorted(df.columns, key=lambda x: int(x.split()[0])) ]\n",
    "    df0 = pd.concat( [df0, df] , axis=0)\n",
    "\n",
    "df0.sort_index(inplace=True)\n",
    "df0.to_csv(f\"{PATH_RAW}/sri_recaudacion.csv\")\n",
    "print(f\"Recaudacion SRI Updated: {df0.index.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391d0fd7-12ac-40b0-932a-3aca15ed7fe6",
   "metadata": {},
   "source": [
    "**SRI**\n",
    "\n",
    "- VAT\n",
    "- Ventas\n",
    "- Vehiculos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c606ed-8429-49f3-80f2-bc6ddebfd1e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# SRI website. Open\n",
    "\n",
    "url = \"https://www.sri.gob.ec/datasets\"\n",
    "r = requests.get(url, headers=hdr, verify=False)\n",
    "r = r.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81771123-af60-4d4f-b7e4-5282fd26cf6f",
   "metadata": {},
   "source": [
    "**Ventas y Compras**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e14321-2faf-4412-a969-59cf92348f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "try :\n",
    "    df = pd.read_csv(f'{PATH_RAW}/sri_ventas.csv', index_col='date', parse_dates=True)\n",
    "except :\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "\n",
    "d = []\n",
    "for i in re.findall('href=[\\'\"]?([^\\'\">]+[\\_0-9].csv)', str(r)) :\n",
    "    if \"ventas\" in i and int(i[-8:-4]) >= pd.to_datetime(df.index.max()).year :\n",
    "        d.append(i)\n",
    "\n",
    "for i in d :\n",
    "    dfi = pd.read_csv( i , sep=\"|\", encoding = 'latin1', decimal=',')\n",
    "    dfi.columns = dfi.columns.str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8').str.lower()\n",
    "    dfi = dfi.rename( columns = {\n",
    "            \"ano\" : \"year\",\n",
    "            \"anio\" : \"year\",\n",
    "            \"mes\" : \"month\",\n",
    "            })\n",
    "    dfi = dfi.loc[:, ~dfi.columns.str.contains('^unnamed')]\n",
    "    dfi.drop(['codigo_sector_n1', 'provincia', 'canton'], axis=1, inplace=True)\n",
    "    dfi[\"date\"] = pd.to_datetime(dfi[['year', 'month']].assign(DAY=1), format='%b')\n",
    "    dfi.drop(['year', 'month'], axis=1, inplace=True)\n",
    "    dfi = dfi.fillna(0).groupby(['date']).apply(lambda x : x.astype(int).sum()).reset_index()\n",
    "    dfi.set_index('date', inplace=True)\n",
    "    \n",
    "    if dfi.index.max() > df.index.max() :\n",
    "        dfi = dfi[dfi.index>df.index.max()]\n",
    "        df = pd.concat([df,dfi], axis=0)\n",
    "        df.sort_index(inplace=True)\n",
    "        print(f\"Updated: {df.index.max()}\")\n",
    "    else :\n",
    "        print(\"Data has not been updated.\")\n",
    "        continue\n",
    "\n",
    "df.to_csv(f'{PATH_RAW}/sri_ventas.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad2adad-76bb-4718-8ed3-072181cd4700",
   "metadata": {},
   "source": [
    "**Vehiculos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6665868c-f051-4ea9-8028-d9e36e69155b",
   "metadata": {},
   "outputs": [],
   "source": [
    "try :\n",
    "    df0 = pd.read_csv(f\"{PATH_RAW}/sri_carsales.csv\", index_col=\"date\", parse_dates=True)\n",
    "    print(f\"Last obs: {df0.index.max()}\")\n",
    "except :\n",
    "    df0 = pd.DataFrame()\n",
    "\n",
    "d = []\n",
    "for i in re.findall('href=[\\'\"]?([^\\'\">]+[\\_0-9].csv)', str(r)) :\n",
    "    if \"vehiculos\" in i.lower() and ( int(i[-8:-4]) >= df0.sri_file.max() ) :\n",
    "        d.append(i)\n",
    "\n",
    "TRANSF = {\n",
    "    \"codigo vehiculo 1\": \"code\",\n",
    "    \"sub categoria 1\": \"subcat_1\",\n",
    "    \"marca\": \"maker\",\n",
    "    \"modelo\" : \"model\",\n",
    "    \"pais\" : \"country\",\n",
    "    \"ano modelo\": \"car_year\",\n",
    "    \"tipo\" : \"type\",\n",
    "    \"clase\" : \"class\",\n",
    "    \"sub clase\" : \"class_sub\",\n",
    "    \"cilindraje\" : \"cylinder\",\n",
    "    \"tipo combustible\": \"fuel\",\n",
    "    \"tipo servicio\": \"service\",\n",
    "    \"codigo color 1\" : \"color_code1\",\n",
    "    \"color 1\" : \"color_code1\",\n",
    "    \"codigo color 2\" : \"color_code2\",\n",
    "    \"color 2\" : \"color_code2\",\n",
    "    \"forma de adquisicion\": \"buy\",\n",
    "    \"forma adquisicion\": \"buy\",\n",
    "    \"tipo transaccion\" : \"buy\",\n",
    "    \"codigo canton\": \"canton_code\",\n",
    "    \"descripcion canton\": \"canton\",\n",
    "    \"mes adquisicion\" : \"month_buy\",\n",
    "    \"mes registro venta\": \"month_registry\",\n",
    "    \"valor avaluo\": \"value\",\n",
    "    \"fecha proceso\" : \"month_registry\",\n",
    "    \"mes  registro venta\": \"month_registry\",\n",
    "    \"mes registro venta\": \"month_registry\",\n",
    "    \"fecha compra\" : \"month_buy\",\n",
    "    \"avaluo\": \"value\",\n",
    "    \"codigo sub categoria\" : \"subcat_1\" ,\n",
    "    \"codigo vehiculo\" : \"code\",\n",
    "    \"categoria\" : \"subcat_1\",\n",
    "    \"persona natural - juridica\" : \"buyer_type\"\n",
    "}\n",
    "\n",
    "xls = pd.ExcelFile(f'{PATH_RAW}/sri_dictionary.xlsx')\n",
    "\n",
    "\n",
    "for u in d :\n",
    "    dfi = pd.read_csv( u , sep=\";\", encoding = 'latin1')\n",
    "    \n",
    "    dfi.columns = dfi.columns.str.lower()\n",
    "    dfi.columns = dfi.columns.str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "    dfi.columns = dfi.columns.str.replace(\" de \", \" \")\n",
    "    dfi.columns = dfi.columns.str.replace(r\"\\(.*\\)\",\"\", regex=True)\n",
    "    dfi.columns = dfi.columns.str.strip()\n",
    "    dfi = dfi.rename( columns = TRANSF )\n",
    "    dfi = dfi.loc[:, ~dfi.columns.str.contains('^unnamed')]\n",
    "\n",
    "    dfi.dropna(how='all', inplace=True)\n",
    "    \n",
    "    dfi['sri_file'] = pd.to_datetime(u[-8:-4]).year\n",
    "    df0 = df0[df0['sri_file']!=dfi.sri_file.max()]\n",
    "\n",
    "    months = {'ene': '01', 'feb': '02', 'mar':'03', 'abr':'04', 'may': '05', 'jun': '06','jul': '07','ago': '08','sep': '09','oct': '10','nov': '11','dic': '12'}\n",
    "    dfi['month_buy'] = pd.to_datetime(dfi['month_buy'].astype(str).str.lower().replace(months, regex=True))\n",
    "    dfi['month_registry'] = dfi['month_registry'].astype(str).str.lower().replace(months, regex=True)\n",
    "    try :\n",
    "        dfi['month_registry'] = pd.to_datetime(dfi['month_registry'], format = '%d/%m/%Y')\n",
    "    except :\n",
    "        dfi['month_registry'] = pd.to_datetime(dfi['month_registry'])\n",
    "        dfi[\"month_registry\"] = dfi[\"month_registry\"].dt.date\n",
    "    \n",
    "    dfi[\"date\"] = pd.to_datetime(dfi[\"month_registry\"])\n",
    "    dfi.set_index(\"date\", inplace=True)\n",
    "\n",
    "    dfi.drop(['canton', 'service'], axis=1, inplace=True)\n",
    "\n",
    "    dfi['value'] = dfi['value'].str.replace(',', '.').astype(float)\n",
    "\n",
    "    for sheet in xls.sheet_names :\n",
    "        if sheet not in dfi.columns : continue\n",
    "\n",
    "        sheet_df = pd.read_excel( f'{PATH_RAW}/sri_dictionary.xlsx' , sheet_name=sheet)\n",
    "        dfi[sheet] = dfi[sheet].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8').str.lower().str.strip()\n",
    "        dfi[sheet] = dfi[sheet].str.replace(r'\\.\\.', '.', regex=True)\n",
    "        dfi[sheet] = dfi[sheet].str.replace('  ', ' ')\n",
    "\n",
    "        mapping_dict = dict(zip(sheet_df[sheet_df.columns[0]], sheet_df[sheet_df.columns[1]]))\n",
    "\n",
    "        # unmatched entries\n",
    "        unmatched_texts = dfi[sheet_df.columns[0]][~dfi[sheet_df.columns[0]].isin(mapping_dict)].unique()\n",
    "        max_code = max(mapping_dict.values()) if mapping_dict else 0\n",
    "        new_entries = {text: max_code + i + 1 for i, text in enumerate(unmatched_texts)}\n",
    "        mapping_dict.update(new_entries)\n",
    "\n",
    "        dfi[sheet_df.columns[0]] = dfi[sheet_df.columns[0]].map(mapping_dict)\n",
    "\n",
    "        dfi[sheet] = pd.to_numeric(dfi[sheet], errors='coerce').astype('Int64')\n",
    "        dfi[sheet] = dfi[sheet].apply(lambda x: '' if pd.isna(x) else x)\n",
    "\n",
    "        updated_sheet_df = pd.DataFrame(list(mapping_dict.items()), columns=[sheet_df.columns[0], sheet_df.columns[1]])\n",
    "        with pd.ExcelWriter( f'{PATH_RAW}/sri_dictionary.xlsx' , mode='a', if_sheet_exists='replace') as writer:\n",
    "            updated_sheet_df.to_excel(writer, sheet_name=sheet, index=False)\n",
    "\n",
    "    for i in [ 'subcat_1', 'code', 'car_year' ] :\n",
    "        dfi[i] = pd.to_numeric(dfi[i], errors='coerce').astype('Int64')\n",
    "        dfi[i] = dfi[i].apply(lambda x: '' if pd.isna(x) else x)\n",
    "\n",
    "    dfi['month_registry'] = pd.to_datetime( dfi['month_registry'] , format='mixed' )\n",
    "    dfi['month_buy'] = pd.to_datetime( dfi['month_buy'] , format='mixed' )\n",
    "    \n",
    "    df0 = pd.concat( [df0,dfi] , axis=0)\n",
    "    print(f\"Updated obs: {df0.index.max()}\")\n",
    "    \n",
    "    df0.to_csv(f\"{PATH_RAW}/sri_carsales.csv\")\n",
    "\n",
    "\n",
    "df = pd.read_csv(f\"{PATH_RAW}/sri_carsales.csv\", parse_dates=True, index_col='date')\n",
    "df = pd.DataFrame( df.resample('MS').size() , columns=['total car sales'] )\n",
    "df.to_csv(f\"{PATH_RAW}/sri_totalcar.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dde368-981a-4485-a608-5574e1f99f83",
   "metadata": {},
   "source": [
    "**IAENP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aace90e4-6769-4373-91d6-940c864d3bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "try :\n",
    "    df0 = pd.read_csv(f\"{PATH_RAW}/sri_iaenp.csv\", index_col=\"date\", parse_dates=True)\n",
    "except :\n",
    "    df0 = pd.DataFrame()\n",
    "    \n",
    "d = []\n",
    "for i in re.findall('href=[\\'\"]?([^\\'\">]+.csv)', str(r)) :\n",
    "    if \"iaenp\" in i.lower() and \"mensual\" in i.lower() :\n",
    "        d.append(i)\n",
    "\n",
    "\n",
    "if len(d)>0 :\n",
    "    dfi = pd.read_csv( d[0] , sep=\";\", encoding = 'latin1', decimal=',')\n",
    "\n",
    "    dfi.columns = dfi.columns.str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8').str.lower()\n",
    "    dfi.rename(columns = { 'ano' : 'year' , 'mes' : 'month'} , inplace=True)\n",
    "    dfi[\"date\"] = pd.to_datetime(dfi[['year', 'month']].assign(DAY=1), format='%b')\n",
    "    dfi.set_index('date', inplace=True)\n",
    "    dfi = dfi.filter(regex='^indice')\n",
    "\n",
    "    for col in dfi.columns :\n",
    "        if \"actividad empresarial no petrolera\" in col :\n",
    "            dfi.rename(columns = {col : 'iaenp'}, inplace=True)\n",
    "\n",
    "    if pd.isnull(df0.index.max()) :\n",
    "        dfi.sort_index(inplace=True)\n",
    "        print(f\"Updated: {dfi.index.max()}\")\n",
    "    elif dfi.index.max() > df0.index.max() :\n",
    "        dfi = dfi[dfi.index>df0.index.max()]\n",
    "        dfi = pd.concat([df0,dfi], axis=0)\n",
    "        dfi.sort_index(inplace=True)\n",
    "        print(f\"Updated: {dfi.index.max()}\")\n",
    "    else :\n",
    "        print(\"Data has not been updated.\")\n",
    "else :\n",
    "    print(\"Data not found.\")\n",
    "\n",
    "dfi.to_csv(f\"{PATH_RAW}/sri_iaenp.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9290df2b-8399-452a-8efa-a2d337c292eb",
   "metadata": {},
   "source": [
    "**VAT -- Impuestos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707d83ac-760f-47b9-9016-d5b22c17b8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.read_csv(f\"{PATH_RAW}/sri_vat.csv\", index_col=[\"date\"],\n",
    "                   parse_dates=True , dtype={\n",
    "                        \"value\" : 'float' \n",
    "                   }\n",
    "                  )\n",
    "\n",
    "d = []\n",
    "for i in re.findall('href=[\\'\"]?([^\\'\">]+[\\_0-9].csv)', str(r)) :\n",
    "    if \"recaudacion\" in i and ( ( int(i[-8:-4]) >= df0.index.year.max() ) or ( int(i[-8:-4]) == df0.index.year.max() and df0.index.month.max() < 12 ) ) :\n",
    "        d.append(i)\n",
    "\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedb10c7-679c-4975-b746-ef245f3e1fc5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_tax_type(tax_type):\n",
    "    patterns = [\n",
    "        (r'\\bimpuesto\\b', 'imp.'),\n",
    "        (r'\\bimp\\b', 'imp.'),\n",
    "        (r'\\bcon\\w*', 'contribuciones'),\n",
    "        (r'\\bamb\\w*', 'ambiental'),\n",
    "        (r'\\bmin\\w*', 'mineras'),\n",
    "        (r'\\bvehic\\w*', 'vehiculos motorizados'),\n",
    "        (r'\\bren\\w*', 'ing extraord. recur. no reno')\n",
    "    ]\n",
    "    for pattern, replacement in patterns:\n",
    "        tax_type = re.sub(pattern, replacement, tax_type, flags=re.IGNORECASE)\n",
    "\n",
    "    return tax_type.strip()\n",
    "\n",
    "for i in d :\n",
    "\n",
    "    dfi = pd.read_csv( i , sep=\"|\", encoding = 'latin1', decimal=',')\n",
    "\n",
    "    dfi.columns= dfi.columns.str.lower()\n",
    "    dfi.rename( columns = {\n",
    "        \"anio\": \"year\",\n",
    "        \"mes\": \"month\",\n",
    "        \"grupo_impuesto\": \"tax_type\",\n",
    "        \"subgrupo_impuesto\" : \"tax_subtype\" ,\n",
    "        \"impuesto\" : \"tax\" ,\n",
    "        \"gran_contribuyente\" : \"contributor_large\" ,\n",
    "        \"sector_n1\" : \"sector\" ,\n",
    "        \"tipo_contribuyente\" : \"contributor_type\" ,\n",
    "        \"valor_recaudado\" : \"value\"\n",
    "        }, inplace=True)\n",
    "\n",
    "    for col in dfi.columns :\n",
    "        if \"anio\" in col : dfi.rename( columns = { col : \"year\" } , inplace=True )\n",
    "    dfi.month = dfi.month.str.extract('(\\d+)')\n",
    "    dfi[\"date\"] = pd.to_datetime(dfi[['year', 'month']].assign(DAY=1))\n",
    "    dfi.drop(['year', 'month'], axis=1, inplace=True)\n",
    "\n",
    "    dfi = dfi.loc[dfi[\"date\"]>df0.index.max()]\n",
    "    dfi.set_index(\"date\", inplace=True)\n",
    "\n",
    "\n",
    "    dfi.drop(['codigo_opera_familia'], axis=1, inplace=True)\n",
    "\n",
    "    cols = ['tax_type', \n",
    "            'tax_subtype',\n",
    "            'tax',\n",
    "            'contributor_large',\n",
    "            'contributor_type',\n",
    "            'provincia',\n",
    "            'canton'\n",
    "           ]\n",
    "    for col in cols :\n",
    "        dfi[col] = dfi[col].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8').str.lower()\n",
    "\n",
    "    dfi['tax_type'] = dfi['tax_type'].apply(clean_tax_type)\n",
    "    dfi['tax_type'] = dfi['tax_type'].str.replace(r'\\.\\.', '.', regex=True)\n",
    "    dfi['tax_type'] = dfi['tax_type'].apply(lambda text: re.sub(r'\\b(ing extraord. recur. no reno)\\b', '', text, flags=re.IGNORECASE).strip())\n",
    "    dfi['tax_type'] = dfi['tax_type'].apply(lambda text: re.sub(r'(?<=\\w)\\.(?!\\s|$)', '. ', text))\n",
    "    dfi['tax_type'] = dfi['tax_type'].str.replace('motorizados motorizados', 'motorizados')\n",
    "\n",
    "    dfi['tax_subtype'] = dfi['tax_subtype'].apply(clean_tax_type)\n",
    "    dfi['tax_subtype'] = dfi['tax_subtype'].str.replace(r'\\.\\.', '.', regex=True)\n",
    "    dfi['tax_subtype'] = dfi['tax_subtype'].apply(lambda text: re.sub(r'\\([^)]*\\)', '', text))\n",
    "    dfi['tax_subtype'] = dfi['tax_subtype'].str.replace(r'imp. ambiental a la contribuciones vehiculos motorizados', 'imp. ambiental a la contaminacion vehicular', regex=True)\n",
    "    dfi['tax_subtype'] = dfi['tax_subtype'].apply(lambda text: re.sub(r'(?<=\\w)\\.(?!\\s|$)', '. ', text))\n",
    "    dfi['tax_subtype'] = dfi['tax_subtype'].apply(lambda text: re.sub('ing extraord. recur. no reno operaciones internas', 'imp. ing. extraord. recur. no renovables', text))\n",
    "\n",
    "    dfi['tax'] = dfi['tax'].apply(clean_tax_type)\n",
    "    dfi['tax'] = dfi['tax'].str.replace(r'\\.\\.', '.', regex=True)\n",
    "    dfi['tax'] = dfi['tax'].apply(lambda text: re.sub(r'\\([^)]*\\)', '', text))\n",
    "    dfi['tax'] = dfi['tax'].apply(lambda text: re.sub(r'(?<=\\w)\\.(?!\\s|$)', '. ', text))\n",
    "\n",
    "    xls = pd.ExcelFile(f'{PATH_RAW}/sri_dictionary.xlsx')\n",
    "\n",
    "    for sheet in xls.sheet_names :\n",
    "        if sheet not in dfi.columns : continue\n",
    "\n",
    "        sheet_df = pd.read_excel( f'{PATH_RAW}/sri_dictionary.xlsx' , sheet_name=sheet)\n",
    "\n",
    "        mapping_dict = dict(zip(sheet_df[sheet_df.columns[0]], sheet_df[sheet_df.columns[1]]))\n",
    "\n",
    "        # unmatched entries\n",
    "        unmatched_texts = dfi[sheet_df.columns[0]][~dfi[sheet_df.columns[0]].isin(mapping_dict)].unique()\n",
    "        max_code = max(mapping_dict.values()) if mapping_dict else 0\n",
    "        new_entries = {text: max_code + i + 1 for i, text in enumerate(unmatched_texts)}\n",
    "        mapping_dict.update(new_entries)\n",
    "\n",
    "        dfi[sheet_df.columns[0]] = dfi[sheet_df.columns[0]].map(mapping_dict)\n",
    "\n",
    "        dfi[sheet] = pd.to_numeric(dfi[sheet], errors='coerce').astype('Int64')\n",
    "        dfi[sheet] = dfi[sheet].apply(lambda x: '' if pd.isna(x) else x)\n",
    "\n",
    "        updated_sheet_df = pd.DataFrame(list(mapping_dict.items()), columns=[sheet_df.columns[0], sheet_df.columns[1]])\n",
    "        with pd.ExcelWriter( f'{PATH_RAW}/sri_dictionary.xlsx' , mode='a', if_sheet_exists='replace') as writer:\n",
    "            updated_sheet_df.to_excel(writer, sheet_name=sheet, index=False)\n",
    "\n",
    "\n",
    "    dfi.rename(columns = {element: f'{element}_code' for i, element in enumerate(xls.sheet_names)}, inplace=True)\n",
    "    df0 = pd.concat([df0, dfi], axis=0)\n",
    "\n",
    "print(f\"Last observation: {df0.index.max()}\")\n",
    "df0.to_csv(f\"{PATH_RAW}/sri_vat.csv\")\n",
    "\n",
    "df0 = df0.resample('MS').agg(sri_vat=('value', 'sum'), sri_transactions=('value', 'size'))\n",
    "df0.to_csv(f\"{PATH_RAW}/sri_vat_timeseries.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229ca706-37bb-417f-85ea-c01d5c1f0692",
   "metadata": {},
   "source": [
    "## CENACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00879a6e-c384-49df-834c-1c10656e21c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# ===============================\n",
    "# Electricity Generation (cenace)\n",
    "url = 'http://www.cenace.gob.ec/wp-content/plugins/ez-addons/data/indicadores.xlsx'\n",
    "df0 = pd.read_excel(requests.get(url=url, verify=False).content, header=0, sheet_name=\"datos\")\n",
    "df0.columns = df0.columns.str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8').str.lower()\n",
    "months = {'enero': '01', 'febrero': '02', 'marzo':'03', 'abril':'04', 'mayo': '05', 'junio': '06','julio': '07','agosto': '08','septiembre': '09','octubre': '10','noviembre': '11','diciembre': '12'}\n",
    "df0['mes'] = df0['mes'].astype(str).str.lower().replace(months, regex=True)\n",
    "df0 = df0.rename(columns={\"ano\": \"year\" , \"mes\" : \"month\"})\n",
    "df0[\"date\"] = pd.to_datetime(df0[[\"year\",\"month\"]].assign(DAY=1))\n",
    "df0 = df0.drop([\"year\",\"month\"], axis=1)\n",
    "df0.set_index(\"date\", inplace=True)\n",
    "\n",
    "df0.rename( columns=lambda x: f\"cenace_{x}\" , inplace=True) \n",
    "\n",
    "df0.to_csv(f'{PATH_RAW}/cenace_power.csv')\n",
    "print(\"Electricity updated\")\n",
    "print(df0.index.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0add2fa2-9651-45a9-92a7-a15b03385390",
   "metadata": {},
   "source": [
    "## Ecuador en Cifras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d9f602-aee4-4fd1-8547-0942da394fb0",
   "metadata": {},
   "source": [
    "**Indices de Precios**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a29cd0f-6a42-4757-867d-f6f75c7e95c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# ========================================\n",
    "# Ecuador en Cifras\n",
    "# ========================================\n",
    "# Indice de Precios al Productor\n",
    "# https://www.ecuadorencifras.gob.ec/indice-de-precios-al-productor-de-disponibilidad-nacional/\n",
    "\n",
    "url = \"https://www.ecuadorencifras.gob.ec/indice-de-precios-al-productor-de-disponibilidad-nacional/\"\n",
    "r = requests.get(url, headers=hdr, verify=False)\n",
    "\n",
    "soup = BeautifulSoup(r.content, 'html.parser')\n",
    "links = soup.find_all('a')\n",
    "\n",
    "links = [ link.get('href') for link in links if link.get('href') is not None and\n",
    "               \"excel\" in link.get('href').lower() ]\n",
    "\n",
    "if len(links) > 0 : get = links[0]\n",
    "else : get = None\n",
    "\n",
    "if get != None :    \n",
    "    file = zipfile.ZipFile((io.BytesIO(urlopen(get).read())))\n",
    "    f = [s for s in file.namelist() if \"generales\" in s]\n",
    "    if len(f) == 1 :\n",
    "        df = pd.read_excel(file.open(f[0]).read(), sheet_name=\"1. Indice_General\")\n",
    "    else :\n",
    "        for i in f :\n",
    "            try : df = pd.read_excel(file.open(i).read(), sheet_name=\"1. Indice_General\")\n",
    "            except: continue\n",
    "    df[\"Unnamed: 0\"] = df[\"Unnamed: 0\"].astype(\"str\").str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8').str.lower()\n",
    "    df.columns = df.loc[df[\"Unnamed: 0\"]==\"anos\"].iloc[0]\n",
    "    df = df[df[\"anos\"].str.isnumeric()==True]\n",
    "    df = pd.melt(df, id_vars=\"anos\", var_name=\"month\")\n",
    "    df = df[df[\"month\"].isnull()==False]\n",
    "    months = {'enero': '01', 'febrero': '02', 'marzo':'03', 'abril':'04', 'mayo': '05', 'junio': '06','julio': '07','agosto': '08','septiembre': '09','octubre': '10','noviembre': '11','diciembre': '12'}\n",
    "    df['month'] = df['month'].astype(str).str.lower().replace(months, regex=True)\n",
    "    df.rename(columns={\"anos\": \"year\", \"value\": \"ipp\"}, inplace=True)\n",
    "    df[\"date\"] = pd.to_datetime(df[[\"year\",\"month\"]].assign(DAY=1))\n",
    "    df.drop(['year', \"month\"], axis=1, inplace=True)\n",
    "    df.set_index(\"date\", drop=True, inplace=True)\n",
    "    df = df[df['ipp'].notna()]\n",
    "    df.to_csv(f\"{PATH_RAW}/ine_ipp.csv\")\n",
    "    print(f\"IPP Updated: {df.index.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cba2a8-2999-4806-8ea0-b633b2ede63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Consumer Price Index\n",
    "# Requires xlrd\n",
    "\n",
    "months = {'enero': '01', 'febrero': '02', 'marzo':'03', 'abril':'04', 'mayo': '05', 'junio': '06','julio': '07','agosto': '08','septiembre': '09','octubre': '10','noviembre': '11','diciembre': '12'}\n",
    "url = \"https://www.ecuadorencifras.gob.ec/indice-de-precios-al-consumidor/\"\n",
    "\n",
    "r = requests.get(url, headers=hdr, verify=False)\n",
    "r = r.content\n",
    "\n",
    "soup = BeautifulSoup(r, 'html.parser')\n",
    "links = soup.find_all('a')\n",
    "\n",
    "links = [ link.get('href') for link in links if link.get('href') is not None and\n",
    "               \"excel\" in link.get('href').lower() ]\n",
    "\n",
    "if len(links) > 0 : get = links[0]\n",
    "else : get = None\n",
    "\n",
    "if get != None :\n",
    "    print(\"Downloading CPI\")\n",
    "    file = zipfile.ZipFile((io.BytesIO(urlopen(get.replace(\" \", \"%20\")).read())))\n",
    "    f = [s for s in file.namelist() if \"serie historica\" in s.lower()]\n",
    "    if len(f) == 1 :\n",
    "        df = pd.read_excel(file.open(f[0]).read(), sheet_name=1)\n",
    "        df[\"Unnamed: 0\"] = df[\"Unnamed: 0\"].astype(\"str\").str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8').str.lower()\n",
    "        df.columns = df.loc[df[\"Unnamed: 0\"]==\"meses\"].iloc[0]\n",
    "        df = df[df[\"meses\"].str.isnumeric()==True]\n",
    "        df = pd.melt(df, id_vars=\"meses\", var_name=\"month\")\n",
    "        df['month'] = df['month'].astype(str).str.lower().replace(months, regex=True)\n",
    "        df.rename(columns={\"meses\": \"year\", \"value\": \"cpi\"}, inplace=True)\n",
    "        df[\"date\"] = pd.to_datetime(df[[\"year\",\"month\"]].assign(DAY=1))\n",
    "        df.drop(['year', \"month\"], axis=1, inplace=True)\n",
    "        df.set_index(\"date\", drop=True, inplace=True)\n",
    "        df = df[df['cpi'].notna()]\n",
    "        df.sort_index(inplace=True)\n",
    "        df.to_csv(f\"{PATH_RAW}/ine_cpi.csv\")\n",
    "        print(f\"CPI Updated: {df.index.max()}\")\n",
    "    else : print(f\"CPI Not Updated\")\n",
    "else : print(f\"CPI Not Found\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dba6865-63bf-434c-8463-bd5557d79515",
   "metadata": {},
   "source": [
    "Estadisticas laborales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c06065-6aa7-4f20-bc1f-09a96fe458b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.ecuadorencifras.gob.ec/estadisticas-laborales-enemdu/\"\n",
    "\n",
    "r = requests.get(url=url, verify=False).content\n",
    "\n",
    "soup = BeautifulSoup(r, 'html.parser')\n",
    "links = soup.find_all('a')\n",
    "\n",
    "excel_links = [ link.get('href') for link in links if\n",
    "               \"xls\" in link.get('href').lower() \n",
    "               and \"tabulados\" in link.get('href').lower() \n",
    "               and \"laboral\" in link.get('href').lower()\n",
    "              ]\n",
    "\n",
    "df = pd.read_excel(excel_links[0], sheet_name = \"1. Poblaciones\", skiprows=1, header=[0,1])\n",
    "df.columns = df.columns.map('{0[0]}_{0[1]}'.format)\n",
    "df.columns = df.columns.astype(\"str\").str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8').str.lower()\n",
    "for col in df.columns :\n",
    "    if \"periodo\" in col : df.rename(columns = {col : 'date'} , inplace=True)\n",
    "    elif \"indicadores\" in col : df.rename(columns = {col : 'indicadores'} , inplace=True)\n",
    "    elif \"total\" in col : df.rename(columns = {col : 'total'} , inplace=True)\n",
    "\n",
    "df.indicadores = df.indicadores.astype(\"str\").str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8').str.lower().str.strip()\n",
    "df = df[['date', 'indicadores', 'total']]\n",
    "\n",
    "months = {'enero': '01', 'febrero': '02', 'marzo':'03', 'abril':'04', 'mayo': '05', 'junio': '06','julio': '07','agosto': '08','septiembre': '09','octubre': '10','noviembre': '11','diciembre': '12', \n",
    "          'ene': '01', 'feb': '02', 'mar':'03', 'abr':'04', 'may': '05', 'jun': '06','jul': '07','ago': '08','sep': '09','oct': '10','nov': '11','dic': '12','dec': '12' }\n",
    "df['date'] = \"01-\" + df['date'].astype(str).str.lower().replace(months, regex=True)\n",
    "\n",
    "df.date = pd.to_datetime(df.date , format= \"%d-%m-%y\")\n",
    "df.set_index('date', inplace=True)\n",
    "\n",
    "target = ['poblacion total', 'poblacion en edad de trabajar (pet)', 'poblacion economicamente activa', 'empleo', 'empleo adecuado/pleno', 'subempleo', 'desempleo' ]\n",
    "df = df[df['indicadores'].isin(target)]\n",
    "\n",
    "df = pd.pivot(df, columns=\"indicadores\", values=\"total\")\n",
    "\n",
    "df.rename( columns=lambda x: f\"enemdu_{x}\" , inplace=True) \n",
    "\n",
    "print(f\"Updated: {df.index.max()}\")\n",
    "df.to_csv(f'{PATH_RAW}/ine_labor.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34dc6c6-802f-45a5-b684-30bd8c62a2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.ecuadorencifras.gob.ec/enemdu-trimestral/\"\n",
    "\n",
    "r = requests.get(url=url, verify=False).content\n",
    "\n",
    "soup = BeautifulSoup(r, 'html.parser')\n",
    "links = soup.find_all('a')\n",
    "\n",
    "excel_links = [ link.get('href') for link in links if\n",
    "               \"xls\" in link.get('href').lower() \n",
    "               and \"tabulados\" in link.get('href').lower() \n",
    "               and \"laboral\" in link.get('href').lower()\n",
    "              ]\n",
    "df = pd.read_excel(excel_links[0], sheet_name = \"1. Poblaciones\", skiprows=1, header=[0,1])\n",
    "df.columns = df.columns.map('{0[0]}_{0[1]}'.format)\n",
    "df.columns = df.columns.astype(\"str\").str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8').str.lower()\n",
    "for col in df.columns :\n",
    "    if \"trimestre\" in col : df.rename(columns = {col : 'date'} , inplace=True)\n",
    "    elif \"indicadores\" in col : df.rename(columns = {col : 'indicadores'} , inplace=True)\n",
    "    elif \"total\" in col : df.rename(columns = {col : 'total'} , inplace=True)\n",
    "\n",
    "df.indicadores = df.indicadores.astype(\"str\").str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8').str.lower().str.strip()\n",
    "df = df[['date', 'indicadores', 'total']]\n",
    "\n",
    "months = {'IV' : '10' , 'III' : '07' , 'II' : '04' , 'I' : \"01\"}\n",
    "df['date'] = df['date'].astype(str).replace(months, regex=True)\n",
    "\n",
    "df.date = \"01-\" + df.date.str.replace(' ', '', regex=True)\n",
    "\n",
    "df.date = pd.to_datetime(df.date , format= \"%d-%m-%Y\")\n",
    "df.set_index('date', inplace=True)\n",
    "\n",
    "target = [ 'poblacion economicamente activa' ]\n",
    "df = df[df['indicadores'].isin(target)]\n",
    "\n",
    "df = pd.pivot(df, columns=\"indicadores\", values=\"total\")\n",
    "\n",
    "df.rename( columns=lambda x: f\"enemdu_{x} trimestral\" , inplace=True) \n",
    "\n",
    "print(f\"Updated: {df.index.max()}\")\n",
    "df.to_csv(f'{PATH_RAW}/ine_pea quarter.csv')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "be2d1da9-a248-4434-a76d-bd5c19f2425c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# No consigo la PEA anual en este archivo solo tasas.\n",
    "\n",
    "url = \"https://www.ecuadorencifras.gob.ec/enemdu-anual/\"\n",
    "\n",
    "r = requests.get(url=url, verify=False).content\n",
    "\n",
    "soup = BeautifulSoup(r, 'html.parser')\n",
    "links = soup.find_all('a')\n",
    "\n",
    "excel_links = [ link.get('href') for link in links if\n",
    "               \"excel\" in link.get('href').lower() \n",
    "               and \"tabulados\" in link.get('href').lower() \n",
    "              ]\n",
    "\n",
    "file = zipfile.ZipFile((io.BytesIO( urlopen(excel_links[0]).read() )))\n",
    "f = [ f for f in file.namelist() if \"Anual\" in f and \"Mercado\" in f and \"Laboral\" in f ]\n",
    "\n",
    "if len(f) == 1 :\n",
    "    df = pd.read_excel(file.open(f[0]).read(), sheet_name=\"2. Territorio\", skiprows=8)\n",
    "    df.columns = df.columns.astype(\"str\").str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8').str.lower()\n",
    "    df.rename(columns = { 'unnamed: 0' : 'year' , 'unnamed: 1' : 'indicadores'} , inplace=True)\n",
    "    df = df[['year', 'indicadores', 'total']]\n",
    "    df.set_index('year', inplace=True)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0ceaf3fa-ee54-4a02-aa21-2b6ea1763589",
   "metadata": {},
   "source": [
    "Pobreza\n",
    "\n",
    "- Incidencia de pobreza por ingreso\n",
    "- Incidencia de pobreza extrema por ingreso\n",
    "- Coeficiente de Gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec88e66a-230f-4f31-80df-7d829c76ba5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.ecuadorencifras.gob.ec/pobreza-por-ingresos/\"\n",
    "\n",
    "r = requests.get(url=url, verify=False).content\n",
    "\n",
    "soup = BeautifulSoup(r, 'html.parser')\n",
    "links = soup.find_all('a')\n",
    "\n",
    "excel_links = [ link.get('href') for link in links if \n",
    "               link.get('href') is not None and\n",
    "               \"tabulados\" in link.get('href').lower() \n",
    "              ]\n",
    "file = zipfile.ZipFile((io.BytesIO( urlopen(excel_links[0]).read() )))\n",
    "f = [ f for f in file.namelist() if \"xlsx\" in f]\n",
    "\n",
    "if len(f)==1: \n",
    "    df = pd.ExcelFile(file.open(f[0]).read())\n",
    "    \n",
    "    sheets = [ '1.1.1.pobre_nacional' , '1.2.1.extpob_nacional', '2.1. Desigualdad_nacional ' ]\n",
    "    df0 = pd.DataFrame()\n",
    "    \n",
    "    for sheet in sheets :\n",
    "        dfi = pd.read_excel(df, sheet_name=sheet, skiprows=8)\n",
    "        dfi.columns = dfi.columns.astype(\"str\").str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8').str.lower()\n",
    "        \n",
    "        if sheet == \"1.1.1.pobre_nacional\" :\n",
    "            COL = 'incidencia (1)'\n",
    "            new_col = 'pobreza'\n",
    "        elif sheet == \"1.2.1.extpob_nacional\" :\n",
    "            COL = 'incidencia (1)'\n",
    "            new_col = 'pobreza_extrema'\n",
    "        elif sheet == \"2.1. Desigualdad_nacional \" :\n",
    "            COL = 'indice de gini'\n",
    "            new_col = 'gini_index'\n",
    "        \n",
    "        dfi.rename(columns = { 'periodo' : 'month' , 'unnamed: 2' : 'year', COL : new_col } , inplace=True)\n",
    "        dfi['month'] = dfi['month'].ffill()\n",
    "        dfi = dfi[['month', 'year', new_col]]\n",
    "        \n",
    "        months = {'enero': '01', 'febrero': '02', 'marzo':'03', 'abril':'04', 'mayo': '05', 'junio': '06','julio': '07','agosto': '08','septiembre': '09','octubre': '10','noviembre': '11','diciembre': '12', \n",
    "                  'ene': '01', 'feb': '02', 'mar':'03', 'abr':'04', 'may': '05', 'jun': '06','jul': '07','ago': '08','sep': '09','oct': '10','nov': '11','dic': '12','dec': '12' }\n",
    "        dfi['month'] = dfi['month'].astype(str).str.lower().replace(months, regex=True)\n",
    "        dfi[new_col] = pd.to_numeric(dfi[new_col], errors='coerce')\n",
    "        dfi.dropna(subset= new_col , inplace=True)\n",
    "        dfi[\"date\"] = pd.to_datetime(dfi[['year', 'month']].assign(DAY=1), format='%b')\n",
    "        \n",
    "        dfi = dfi.set_index('date')[[new_col]]\n",
    "        \n",
    "        dfi.sort_index(inplace=True)\n",
    "        df0 = pd.concat([df0, dfi], axis=1)\n",
    "    \n",
    "    df0.rename( columns=lambda x: f\"enemdu_{x}\" , inplace=True) \n",
    "    print(f\"Updated: {df0.index.max()}\")\n",
    "    df0.to_csv(f'{PATH_RAW}/ine_pobreza.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18709b99-d168-4af3-9cd0-6e83e2500bec",
   "metadata": {},
   "source": [
    "## FINANZAS\n",
    "\n",
    "(Works on selenium +4.6)\n",
    "\n",
    "```\n",
    "conda install selenium==4.6.0\n",
    "conda install selenium==4.25.0\n",
    "```\n",
    "Chrome driver: https://googlechromelabs.github.io/chrome-for-testing/#stable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035ca176-5fd5-4287-8643-e1386a5c7217",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.finanzas.gob.ec/estadistica-nueva-metodologia-2013-2022/\"\n",
    "headers = { 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3' }\n",
    "\n",
    "r = requests.get(url=url, verify=False, headers=headers).content\n",
    "soup = BeautifulSoup(r, 'html.parser')\n",
    "links = soup.find_all('a')\n",
    "\n",
    "links = [ link for link in links if link.get('data-type') is not None and \"Operaciones de Ingresos\" in link.contents[0] ]\n",
    "\n",
    "max_id = -1\n",
    "latest_link = None\n",
    "\n",
    "for link in links:\n",
    "    href = link['href']\n",
    "    \n",
    "    id_str = href.split('=')[-1]\n",
    "    id_int = int(id_str)\n",
    "    # Compare and store the link with the highest ID\n",
    "    if id_int > max_id:\n",
    "        max_id = id_int\n",
    "        latest_link = href"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec7831b-6c43-425e-be27-3bd6d974cb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import shutil\n",
    "import time\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "download_folder = \"C:/Users/guerr/Downloads/\"\n",
    "\n",
    "#chromeOptions = webdriver.ChromeOptions()\n",
    "#prefs = {\"download.default_directory\" : r\"C:\\\\Users\\\\guerr\\\\Dropbox\\\\20240501 BID Nowcasting LATAM\\\\ecuador\\\\raw\"}\n",
    "#chromeOptions.add_experimental_option(\"prefs\", prefs)\n",
    "#driver = webdriver.Chrome(options=chromeOptions)\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(latest_link)\n",
    "time.sleep(10)\n",
    "driver.quit()\n",
    "\n",
    "\n",
    "target = [ f for f in os.listdir(download_folder) if \"SPNF\" in f]\n",
    "if len(target) > 0 :\n",
    "    target = target[0]\n",
    "    shutil.move(f\"{download_folder}/{target}\", f\"{PATH_RAW}/{target}\")\n",
    "\n",
    "dfi = pd.read_excel(f\"{PATH_RAW}/{target}\" , sheet_name=\"SPNF\", skiprows=5, header = [0,1])\n",
    "dfi.columns = dfi.columns.map('{0[0]}_{0[1]}'.format)\n",
    "dfi.columns = dfi.columns.astype(\"str\").str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8').str.lower()\n",
    "\n",
    "t = [ \"codigo\" , \"transacciones\" , \"mensual\" ]\n",
    "dfi = dfi[[col for col in dfi.columns if any(target in col for target in t)]]\n",
    "\n",
    "for col in dfi :\n",
    "    if \"codigo\" in col : dfi.rename( columns = { col : 'codigo' } , inplace=True)\n",
    "    elif \"transacciones\" in col : dfi.rename( columns = { col : 'transacciones' } , inplace=True)\n",
    "dfi.columns = dfi.columns.str.replace('mensual_', '', regex=False)\n",
    "\n",
    "dfi.codigo = pd.to_numeric(dfi['codigo'], errors='coerce')\n",
    "dfi = dfi[(dfi['codigo'] < 100)]\n",
    "\n",
    "dfi.drop('codigo', axis=1, inplace=True)\n",
    "\n",
    "dfi = pd.melt(dfi, id_vars=\"transacciones\", var_name=\"date\")\n",
    "dfi.date = pd.to_datetime(dfi.date)\n",
    "dfi.transacciones = dfi.transacciones.astype(\"str\").str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8').str.lower()\n",
    "dfi['transacciones'] = dfi['transacciones'].str.replace(r'\\(.*?\\)', '', regex=True).str.lower().str.strip().str.replace(\" \", \"_\")\n",
    "\n",
    "dfi.set_index('date', inplace=True)\n",
    "dfi = pd.pivot(dfi, columns=\"transacciones\", values=\"value\")\n",
    "\n",
    "dfi.rename( columns=lambda x: f\"spnf_{x}\" , inplace=True) \n",
    "print(f\"Updated: {dfi.index.max()}\")\n",
    "dfi.to_csv(f'{PATH_RAW}/mef_spnf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c77005-5936-4bd1-a8c9-647ab88fd093",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfi = pd.read_excel(f\"{PATH_RAW}/{target}\" , sheet_name=\"GC\", skiprows=5, header = [0,1])\n",
    "dfi.columns = dfi.columns.map('{0[0]}_{0[1]}'.format)\n",
    "dfi.columns = dfi.columns.astype(\"str\").str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8').str.lower()\n",
    "\n",
    "t = [ \"codigo\" , \"transacciones\" , \"mensual\" ]\n",
    "dfi = dfi[[col for col in dfi.columns if any(target in col for target in t)]]\n",
    "\n",
    "for col in dfi :\n",
    "    if \"codigo\" in col : dfi.rename( columns = { col : 'codigo' } , inplace=True)\n",
    "    elif \"transacciones\" in col : dfi.rename( columns = { col : 'transacciones' } , inplace=True)\n",
    "dfi.columns = dfi.columns.str.replace('mensual_', '', regex=False)\n",
    "\n",
    "dfi.codigo = pd.to_numeric(dfi['codigo'], errors='coerce')\n",
    "dfi = dfi[(dfi['codigo'] < 100)]\n",
    "\n",
    "dfi.drop('codigo', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "dfi = pd.melt(dfi, id_vars=\"transacciones\", var_name=\"date\")\n",
    "dfi.date = pd.to_datetime(dfi.date)\n",
    "dfi.transacciones = dfi.transacciones.astype(\"str\").str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8').str.lower()\n",
    "dfi['transacciones'] = dfi['transacciones'].str.replace(r'\\(.*?\\)', '', regex=True).str.lower().str.strip().str.replace(\" \", \"_\")\n",
    "\n",
    "dfi.set_index('date', inplace=True)\n",
    "dfi = pd.pivot(dfi, columns=\"transacciones\", values=\"value\")\n",
    "\n",
    "dfi.rename( columns=lambda x: f\"gc_{x}\" , inplace=True) \n",
    "print(f\"Updated: {dfi.index.max()}\")\n",
    "dfi.to_csv(f'{PATH_RAW}/mef_gc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1931a34-ea83-43fe-9e2b-7b66b6d79b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "try :\n",
    "    os.remove( f\"{PATH_RAW}/{target}\" )\n",
    "    print(f\"{target} has been deleted.\")\n",
    "except :\n",
    "    print(f\"{target} not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ddf208-2b10-4269-aff5-021c8c6e31dc",
   "metadata": {},
   "source": [
    "**Deuda Publica**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6490cab8-c4f6-413b-a1d5-1be9c1dd95ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.read_csv(f\"{PATH_RAW}/mef_deuda.csv\", parse_dates=True, index_col='date')\n",
    "\n",
    "last_date = df0.index.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59108d0b-bc35-443d-b2d5-07cc155157e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import shutil\n",
    "import time\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "download_folder = \"C:/Users/guerr/Downloads/\"\n",
    "\n",
    "# URL de la pgina que contiene los archivos\n",
    "url = \"https://www.finanzas.gob.ec/https-wwwdeuda-publica-nueva-metodologia/\"  # Reemplaza con la URL real\n",
    "\n",
    "# Realizar la solicitud y parsear el HTML\n",
    "r = requests.get(url=url, verify=False, headers=hdr,timeout=20).content\n",
    "soup = BeautifulSoup(r, 'html.parser')\n",
    "\n",
    "# Encontrar todos los enlaces\n",
    "links = soup.find_all('a')\n",
    "filtered_links = [ link for link in links if link.text.startswith(\"Base de Datos\") ]\n",
    "months = {'enero': '01', 'febrero': '02', 'marzo':'03', 'abril':'04', 'mayo': '05', 'junio': '06','julio': '07','agosto': '08','septiembre': '09','octubre': '10','noviembre': '11','diciembre': '12', \n",
    "                  'ene': '01', 'feb': '02', 'mar':'03', 'abr':'04', 'may': '05', 'jun': '06','jul': '07','ago': '08','sep': '09','oct': '10','nov': '11','dic': '12','dec': '12' }\n",
    "\n",
    "# Remover links que ya estan en los datos\n",
    "links = list()\n",
    "for x in filtered_links :\n",
    "    m , y = x.contents[-1].lower().split()[-2], x.contents[-1].lower().split(\" \")[-1]\n",
    "    try :\n",
    "        m = months[m]\n",
    "        d = pd.to_datetime(f\"01-{m}-{y}\", format = \"%d-%m-%Y\")\n",
    "        if d > last_date :\n",
    "            links.append(x['href'])\n",
    "    except :\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdff7ec-9016-4279-83b8-848d0fe38b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in links :\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(link)\n",
    "    time.sleep(10)\n",
    "    driver.quit()\n",
    "\n",
    "target = [ f for f in os.listdir(download_folder) if\n",
    "          ( \"base-\" in f.lower() or \"cuaderno-\" in f.lower() or \"base\" in f.lower() ) \n",
    "          and ( 'xls' in f ) ]\n",
    "if len(target) > 0:\n",
    "    for f in target:\n",
    "        shutil.move(f\"{download_folder}/{f}\", f\"{PATH_RAW}/{f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58de788d-04bf-4b63-8362-c8a87d9c1b3d",
   "metadata": {},
   "source": [
    "Identificar que archivos se necesitan actualizar. Borrar el resto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d275ac5-e769-48bf-a5b2-bf88c50ae9e5",
   "metadata": {},
   "source": [
    "Actualizacion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4c28d4-7739-4b78-b565-4390da31beb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target = [ f for f in os.listdir(f\"{PATH_RAW}\") if\n",
    "          ( \"base-\" in f.lower() or \"cuaderno-\" in f.lower() or \"base\" in f.lower() ) \n",
    "          and ( 'xls' in f ) ]\n",
    "\n",
    "\n",
    "for t in target :\n",
    "    with pd.ExcelFile(f\"{PATH_RAW}/{t}\") as xls:\n",
    "        df = pd.ExcelFile(xls)\n",
    "    \n",
    "    mysheet = [ x for x in df.sheet_names if \"spnf\" in x.lower() and \"cons\" in x.lower()]\n",
    "    if len(mysheet)>0 :\n",
    "        mysheet=mysheet[0]\n",
    "        \n",
    "        dfi = pd.read_excel( \n",
    "            df ,\n",
    "            sheet_name=mysheet, \n",
    "            skiprows=4\n",
    "        )\n",
    "        \n",
    "        dfi.columns = dfi.columns.astype(\"str\").str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8').str.lower()\n",
    "        dfi['deuda externa'] = dfi['deuda externa'].astype(\"str\").str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8').str.lower()\n",
    "        dfi = dfi[dfi['deuda externa'].astype(str).str.startswith('total deuda publica')]\n",
    "        dfi = dfi[[ col for col in dfi.columns if \"deuda externa\" in col or \"saldo al\" in col ]]\n",
    "        \n",
    "        dfi = pd.melt(dfi, id_vars=\"deuda externa\", var_name=\"date\")\n",
    "        dfi['date'] = dfi['date'].astype(str).str.replace(\"-\", \"/\").str.replace(\".\", \"/\")\n",
    "        dfi['date'] = dfi['date'].str.replace(r'[a-z\\s+]', r'', regex=True)\n",
    "        dfi.date = pd.to_datetime(dfi.date)\n",
    "        dfi.set_index('date', inplace=True)\n",
    "        dfi[dfi.index==dfi.index.max()]\n",
    "        \n",
    "        dfi = pd.pivot(dfi, columns=\"deuda externa\", values=\"value\")\n",
    "        dfi.rename( columns=lambda x: f\"spnf consolidada {x}\" , inplace=True) \n",
    "    else :\n",
    "        notfound.append(t)\n",
    "        \n",
    "    mysheet = [\n",
    "        x for x in df.sheet_names if\n",
    "        \"spnf\" in x.lower() \n",
    "        and \"acree\" in x.lower()\n",
    "        and \"-F\" not in x\n",
    "    ]\n",
    "    if len(mysheet)>0 :\n",
    "        mysheet=mysheet[0]\n",
    "        \n",
    "        dfk = pd.read_excel( \n",
    "            df ,\n",
    "            sheet_name=mysheet, \n",
    "            skiprows=4\n",
    "        )\n",
    "        \n",
    "        dfk.columns = dfk.columns.astype(\"str\").str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8').str.lower()\n",
    "        dfk['deuda externa'] = dfk['deuda externa'].astype(\"str\").str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8').str.lower()\n",
    "        dfk = dfk[dfk['deuda externa'].astype(str).str.startswith('total deuda publica')]\n",
    "        dfk = dfk[[ col for col in dfk.columns if \"deuda externa\" in col or \"saldo al\" in col ]]\n",
    "        \n",
    "        dfk = pd.melt(dfk, id_vars=\"deuda externa\", var_name=\"date\")\n",
    "        dfk['date'] = dfk['date'].astype(str).str.replace(\"-\", \"/\").str.replace(\".\", \"/\")\n",
    "        dfk['date'] = dfk['date'].str.replace(r'[a-z\\s+]', r'', regex=True)\n",
    "        dfk.date = pd.to_datetime(dfk.date)\n",
    "        dfk.set_index('date', inplace=True)\n",
    "        dfk[dfk.index==dfk.index.max()]\n",
    "        \n",
    "        dfk = pd.pivot(dfk, columns=\"deuda externa\", values=\"value\")\n",
    "        dfk.rename( columns=lambda x: f\"spnf agg {x}\" , inplace=True) \n",
    "    \n",
    "    df = pd.concat( [dfi, dfk ] , axis=1 )\n",
    "    df0 = pd.concat( [ df0, df ], axis=0).sort_index()\n",
    "    os.remove(f\"{PATH_RAW}/{t}\")\n",
    "\n",
    "df0 = df0.resample('MS').last()\n",
    "df0.to_csv(f\"{PATH_RAW}/mef_deuda.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffb2a4a-139d-4c62-8a29-5d58fe684dab",
   "metadata": {},
   "source": [
    "**COSEDE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf24961-8511-4c57-a0a6-f1ab18c80833",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.cosede.gob.ec/publicaciones-estadisticas-mensuales-pem/\"\n",
    "\n",
    "r = requests.get(url=url, verify=False, headers=hdr).content\n",
    "soup = BeautifulSoup(r, 'html.parser')\n",
    "links = soup.find_all('a')\n",
    "\n",
    "links = [ link.get('href') for link in links if \"xlsx\" in link.get('href') if \"liquidez\" in link.get('href').lower() and ( \"historico\" in link.get('href').lower() or \"histrico\" in link.get('href').lower() ) ]\n",
    "links = max(links, key=lambda s: int(re.search(r'PEM-(\\d+)-', s).group(1)))\n",
    "\n",
    "df = pd.ExcelFile(links)\n",
    "df = pd.read_excel(df, sheet_name='FLSFP', skiprows=9, skipfooter=3)\n",
    "df.columns = df.columns.astype(\"str\").str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8').str.lower()\n",
    "\n",
    "df.rename(columns = {'unnamed: 2' : 'year'}, inplace=True)\n",
    "df = df[[ col for col in df.columns if \"unnamed\" not in col ]]\n",
    "\n",
    "df = pd.melt(df, id_vars='year', var_name='month', value_name='cosede_liquidez')\n",
    "df['month'] = df['month'].astype(str).str.lower().replace(months, regex=True)\n",
    "df['date'] = pd.to_datetime(df[['year', 'month']].assign(DAY=1), format='%b')\n",
    "df = df[['cosede_liquidez', 'date']]\n",
    "df.set_index('date', inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "df.sort_index(inplace=True)\n",
    "\n",
    "print(f\"Updated: {df.index.max()}\")\n",
    "df.to_csv(f'{PATH_RAW}/cosede_lfsfp.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25a7407-fddf-435e-be35-6bba31f21bd5",
   "metadata": {},
   "source": [
    "## Merge Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcea1545-cc8f-4689-a332-911e9bce61b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "files = glob.glob(f'{PATH_FORMAT}/*.csv')\n",
    "for f in files:\n",
    "    os.remove(f)\n",
    "\n",
    "dict = pd.read_excel(f'{PATH_RAW}/dict.xlsx')\n",
    "for col in dict.columns : dict[col] = dict[col].astype(str).str.strip()\n",
    "\n",
    "defined = dict[['ticket', 'definition', 'source']].set_index('ticket')\n",
    "defined = pd.DataFrame({'definition' : defined.apply(lambda row: f\"Definition: {row['definition']}. Source: {row['source']}\", axis=1)})\n",
    "defined = defined['definition'].to_dict()\n",
    "\n",
    "dict = pd.read_excel(f'{PATH_RAW}/dict.xlsx')[['ticket', 'var name', 'file']]\n",
    "file_list = [ csv for csv in os.listdir(f\"{PATH_RAW}\") if \"csv\" in csv and csv in dict.file.unique() ]\n",
    "dict = dict.set_index('var name')['ticket'].to_dict()\n",
    "\n",
    "for file in file_list :\n",
    "    dfi = pd.read_csv(f\"{PATH_RAW}/{file}\" , parse_dates=True, index_col='date')\n",
    "    dfi.rename(columns=dict , inplace=True)\n",
    "    dfi = dfi[[col for col in dfi.columns if col in dict.values()]]\n",
    "    \n",
    "    for col in dfi.columns:\n",
    "        dfi[[col]].to_csv(f\"{PATH_FORMAT}/{col}.csv\", index=True)\n",
    "        with open(f\"{PATH_FORMAT}/{col}.csv\", 'a') as output :\n",
    "            output.write(f\"\\n\\n {defined[col]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccebfb3-6b6e-4b8e-a183-987ff9cb2fa0",
   "metadata": {},
   "source": [
    "List any file that was not added:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928fef18-bbce-4674-9bdd-1574cd3caaea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[ x for x in list(dict.values()) if x+\".csv\" not in os.listdir(PATH_FORMAT) ]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
